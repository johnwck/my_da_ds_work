{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541e0a45",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 1: Import</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bf7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b3e9d",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 2: Read, drop columns, form X_train and y_train</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55c2d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop : (882, 51)\n",
      "After drop: (882, 42)\n",
      "\n",
      "X_train : (882, 41)\n",
      "y_train : (882,)\n",
      "\n",
      "y_train : (array([0., 1.]), array([763, 119], dtype=int64))\n",
      "y_train : Counter({0.0: 763, 1.0: 119})\n",
      "0.0    0.865079\n",
      "1.0    0.134921\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ---------- read ----------\n",
    "\n",
    "df_1 = pd.read_csv('../data/code_3_train.csv')\n",
    "\n",
    "# ---------- drop ----------\n",
    "\n",
    "print('Before drop :', df_1.shape)\n",
    "df_1.drop(columns=['index',\n",
    "                   'pco2', 'ph', 'basophils', 'lactic_acid', 'bmi',\n",
    "                   'creatine_kinase', 'lymphocyte', 'neutrophils'], inplace=True)\n",
    "print('After drop:', df_1.shape)\n",
    "print('')\n",
    "\n",
    "# ---------- form X ----------\n",
    "\n",
    "X_train = df_1.drop(columns=['outcome'])\n",
    "print('X_train :', X_train.shape)\n",
    "\n",
    "# ---------- form y ----------\n",
    "\n",
    "y_train = df_1['outcome']\n",
    "print('y_train :', y_train.shape)\n",
    "print('')\n",
    "print('y_train :', np.unique(y_train, return_counts=True))\n",
    "print('y_train :', Counter(y_train))\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7648523",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 3: Set up 15-fold cross validation</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9e2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588c06b",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 4: Explore Decision Tree Classifier</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eeb84de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : [0.62437259 0.1957958  0.31144895 0.31144895 0.31144895 0.31144895\n",
      " 0.62437259 0.1957958  0.48682432 0.57431896 0.64650901 0.66152402\n",
      " 0.62437259 0.1957958  0.48682432 0.52386851 0.54911519 0.55103496\n",
      " 0.62437259 0.1957958  0.48682432 0.52386851 0.5587248  0.54082475\n",
      " 0.62437259 0.1957958  0.48682432 0.52386851 0.5587248  0.54623016\n",
      " 0.62437259 0.1957958  0.48682432 0.52386851 0.5587248  0.54623016]\n",
      "Validation : [0.54404762 0.15833333 0.27142857 0.27142857 0.27142857 0.27142857\n",
      " 0.54404762 0.15833333 0.4297619  0.46309524 0.52738095 0.53571429\n",
      " 0.54404762 0.15833333 0.4297619  0.39642857 0.3797619  0.40238095\n",
      " 0.54404762 0.15833333 0.4297619  0.39642857 0.4047619  0.40238095\n",
      " 0.54404762 0.15833333 0.4297619  0.39642857 0.4047619  0.39404762\n",
      " 0.54404762 0.15833333 0.4297619  0.39642857 0.4047619  0.39404762]\n",
      "Overfit %: [-12.86490943 -19.13343558 -12.84973915 -12.84973915 -12.84973915\n",
      " -12.84973915 -12.86490943 -19.13343558 -11.72135752 -19.3661939\n",
      " -18.42635678 -19.0181662  -12.86490943 -19.13343558 -11.72135752\n",
      " -24.32670359 -30.8411215  -26.97723756 -12.86490943 -19.13343558\n",
      " -11.72135752 -24.32670359 -27.55612289 -25.59864357 -12.86490943\n",
      " -19.13343558 -11.72135752 -24.32670359 -27.55612289 -27.8605158\n",
      " -12.86490943 -19.13343558 -11.72135752 -24.32670359 -27.55612289\n",
      " -27.8605158 ]\n",
      "\n",
      "                                            parameters  max_depth  \\\n",
      "0    {'dt_class__max_depth': 2, 'dt_class__max_leaf...          2   \n",
      "1    {'dt_class__max_depth': 2, 'dt_class__max_leaf...          2   \n",
      "2    {'dt_class__max_depth': 2, 'dt_class__max_leaf...          2   \n",
      "3    {'dt_class__max_depth': 2, 'dt_class__max_leaf...          2   \n",
      "4    {'dt_class__max_depth': 2, 'dt_class__max_leaf...          2   \n",
      "..                                                 ...        ...   \n",
      "535  {'dt_class__max_depth': 7, 'dt_class__max_leaf...          7   \n",
      "536  {'dt_class__max_depth': 7, 'dt_class__max_leaf...          7   \n",
      "537  {'dt_class__max_depth': 7, 'dt_class__max_leaf...          7   \n",
      "538  {'dt_class__max_depth': 7, 'dt_class__max_leaf...          7   \n",
      "539  {'dt_class__max_depth': 7, 'dt_class__max_leaf...          7   \n",
      "\n",
      "     max_leaf_nodes  training  validation  overfit_%  \n",
      "0                 2  0.603604    0.500000 -17.164179  \n",
      "1                 2  0.738739    0.750000   1.524390  \n",
      "2                 2  0.594595    0.625000   5.113636  \n",
      "3                 2  0.765766    0.375000 -51.029412  \n",
      "4                 2  0.747748    0.500000 -33.132530  \n",
      "..              ...       ...         ...        ...  \n",
      "535               7  0.648649    0.625000  -3.645833  \n",
      "536               7  0.495495    0.625000  26.136364  \n",
      "537               7  0.720721    0.125000 -82.656250  \n",
      "538               7  0.396396    0.250000 -36.931818  \n",
      "539               7  0.526786    0.285714 -45.762712  \n",
      "\n",
      "[540 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fcd01c59ed7d>:35: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  over_fit = (search_dt.cv_results_['split'+str(i)+'_test_score'][j]-search_dt.cv_results_['split'+str(i)+'_train_score'][j])/search_dt.cv_results_['split'+str(i)+'_train_score'][j]*100\n"
     ]
    }
   ],
   "source": [
    "# ---------- make pipeline ----------\n",
    "\n",
    "pipe_line_dt = Pipeline([('knn_impute', KNNImputer(n_neighbors=5)),\n",
    "                         ('oversample_SMOTE', SMOTE(random_state=42)),\n",
    "                         ('ss_scale', StandardScaler()),\n",
    "                         ('dt_class', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# ---------- tuning of hyperparameters ----------\n",
    "\n",
    "pipe_line_params_dt = {'dt_class__max_depth': [2,3,4,5,6,7],\n",
    "                       'dt_class__max_leaf_nodes': [2,3,4,5,6,7]}\n",
    "\n",
    "# ---------- instantiate gridsearchcv for recall in accordance to aim of modelling ----------\n",
    "\n",
    "search_dt = GridSearchCV(pipe_line_dt,\n",
    "                         param_grid=pipe_line_params_dt,\n",
    "                         cv=kfold_cv,\n",
    "                         return_train_score=True,\n",
    "                         scoring='recall')\n",
    "\n",
    "search_dt.fit(X_train, y_train)\n",
    "\n",
    "# ---------- quick overview of recall train score, test score and overfit ----------\n",
    "\n",
    "print('Training :', search_dt.cv_results_['mean_train_score'])\n",
    "print('Validation :', search_dt.cv_results_['mean_test_score'])\n",
    "print('Overfit %:', (search_dt.cv_results_['mean_test_score']-search_dt.cv_results_['mean_train_score'])/search_dt.cv_results_['mean_train_score']*100)\n",
    "print('')\n",
    "\n",
    "# ---------- details of recall train score and test score ----------\n",
    "\n",
    "temp_df_dt = []\n",
    "for j in range(len(search_dt.cv_results_['params'])):\n",
    "    for i in range(kfold_cv.n_splits):\n",
    "        over_fit = (search_dt.cv_results_['split'+str(i)+'_test_score'][j]-search_dt.cv_results_['split'+str(i)+'_train_score'][j])/search_dt.cv_results_['split'+str(i)+'_train_score'][j]*100\n",
    "        temp_df_dt.append([search_dt.cv_results_['params'][j],\n",
    "                           search_dt.cv_results_['params'][j]['dt_class__max_depth'],\n",
    "                           search_dt.cv_results_['params'][j]['dt_class__max_leaf_nodes'],\n",
    "                           search_dt.cv_results_['split'+str(i)+'_train_score'][j],\n",
    "                           search_dt.cv_results_['split'+str(i)+'_test_score'][j],\n",
    "                           over_fit])\n",
    "temp_df_dt = pd.DataFrame(temp_df_dt, columns=['parameters', 'max_depth', 'max_leaf_nodes', 'training', 'validation', 'overfit_%'])\n",
    "print(temp_df_dt)\n",
    "temp_df_dt.to_csv('../data/code_5a_dt_train_validate_recall.csv', na_rep='NaN', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f7850",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Severe overfitting with Decision Tree Classifier.</span>  \n",
    "<br>  \n",
    "<br>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c2780",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 5: Explore Random Forest Classifier</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ca8c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : [0.53907121 0.62669455 0.62429215 0.63987559 0.64228335 0.64407979\n",
      " 0.59603711 0.62483912 0.64762441 0.66984663 0.68786465 0.71127735\n",
      " 0.62065101 0.69384384 0.68724796 0.69804269 0.70109395 0.70949163\n",
      " 0.6524882  0.7365133  0.74910446 0.749142   0.75994745 0.77915058\n",
      " 0.72453882 0.78396075 0.80496032 0.82056521 0.83495817 0.8517589\n",
      " 0.76594273 0.8361701  0.86680609 0.87638889 0.88540862 0.9021879 ]\n",
      "Validation : [0.48809524 0.54642857 0.56309524 0.5797619  0.5547619  0.56309524\n",
      " 0.50595238 0.5547619  0.48928571 0.54761905 0.55595238 0.52261905\n",
      " 0.46071429 0.52261905 0.4952381  0.47142857 0.4797619  0.4797619\n",
      " 0.41428571 0.48214286 0.47380952 0.45714286 0.51428571 0.47261905\n",
      " 0.41904762 0.44404762 0.3952381  0.43690476 0.3952381  0.42142857\n",
      " 0.30119048 0.40119048 0.35952381 0.39285714 0.37738095 0.37619048]\n",
      "Overfit %: [ -9.45626007 -12.80783119  -9.80260784  -9.39458952 -13.62661034\n",
      " -12.57368368 -15.11394614 -11.21524202 -24.449155   -18.24709998\n",
      " -19.17706766 -26.52387307 -25.76918757 -24.67771354 -27.93895036\n",
      " -32.46422014 -31.56952731 -32.37948392 -36.50678852 -34.53711457\n",
      " -36.74987294 -38.97780959 -32.32614755 -39.34175752 -42.1635384\n",
      " -43.35843713 -50.89967957 -46.75563165 -52.66372517 -50.52255156\n",
      " -60.67715444 -52.02047086 -58.52315611 -55.17319448 -57.37776405\n",
      " -58.30242511]\n",
      "\n",
      "                                            parameters  max_depth  \\\n",
      "0    {'rf_class__max_depth': 2, 'rf_class__n_estima...          2   \n",
      "1    {'rf_class__max_depth': 2, 'rf_class__n_estima...          2   \n",
      "2    {'rf_class__max_depth': 2, 'rf_class__n_estima...          2   \n",
      "3    {'rf_class__max_depth': 2, 'rf_class__n_estima...          2   \n",
      "4    {'rf_class__max_depth': 2, 'rf_class__n_estima...          2   \n",
      "..                                                 ...        ...   \n",
      "535  {'rf_class__max_depth': 7, 'rf_class__n_estima...          7   \n",
      "536  {'rf_class__max_depth': 7, 'rf_class__n_estima...          7   \n",
      "537  {'rf_class__max_depth': 7, 'rf_class__n_estima...          7   \n",
      "538  {'rf_class__max_depth': 7, 'rf_class__n_estima...          7   \n",
      "539  {'rf_class__max_depth': 7, 'rf_class__n_estima...          7   \n",
      "\n",
      "     n_estimators  training  validation  overfit_%  \n",
      "0               2  0.657658    0.125000 -80.993151  \n",
      "1               2  0.531532    0.750000  41.101695  \n",
      "2               2  0.567568    0.625000  10.119048  \n",
      "3               2  0.531532    0.250000 -52.966102  \n",
      "4               2  0.522523    0.250000 -52.155172  \n",
      "..            ...       ...         ...        ...  \n",
      "535             7  0.882883    0.625000 -29.209184  \n",
      "536             7  0.927928    0.500000 -46.116505  \n",
      "537             7  0.882883    0.500000 -43.367347  \n",
      "538             7  0.918919    0.375000 -59.191176  \n",
      "539             7  0.857143    0.142857 -83.333333  \n",
      "\n",
      "[540 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------- make pipeline ----------\n",
    "\n",
    "pipe_line_rf = Pipeline([('knn_impute', KNNImputer(n_neighbors=5)),\n",
    "                         ('oversample_SMOTE', SMOTE(random_state=42)),\n",
    "                         ('ss_scale', StandardScaler()),\n",
    "                         ('rf_class', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# ---------- tuning of hyperparameters ----------\n",
    "\n",
    "pipe_line_params_rf = {'rf_class__max_depth': [2,3,4,5,6,7],\n",
    "                       'rf_class__n_estimators': [2,3,4,5,6,7]}\n",
    "\n",
    "# ---------- instantiate gridsearchcv for recall in accordance to aim of modelling ----------\n",
    "\n",
    "search_rf = GridSearchCV(pipe_line_rf,\n",
    "                         param_grid=pipe_line_params_rf,\n",
    "                         cv=kfold_cv,\n",
    "                         return_train_score=True,\n",
    "                         scoring='recall')\n",
    "\n",
    "search_rf.fit(X_train, y_train)\n",
    "\n",
    "# ---------- quick overview of recall train score, test score and overfit ----------\n",
    "\n",
    "print('Training :', search_rf.cv_results_['mean_train_score'])\n",
    "print('Validation :', search_rf.cv_results_['mean_test_score'])\n",
    "print('Overfit %:', (search_rf.cv_results_['mean_test_score']-search_rf.cv_results_['mean_train_score'])/search_rf.cv_results_['mean_train_score']*100)\n",
    "print('')\n",
    "\n",
    "# ---------- details of recall train score and test score ----------\n",
    "\n",
    "temp_df_rf = []\n",
    "for j in range(len(search_rf.cv_results_['params'])):\n",
    "    for i in range(kfold_cv.n_splits):\n",
    "        over_fit = (search_rf.cv_results_['split'+str(i)+'_test_score'][j]-search_rf.cv_results_['split'+str(i)+'_train_score'][j])/search_rf.cv_results_['split'+str(i)+'_train_score'][j]*100\n",
    "        temp_df_rf.append([search_rf.cv_results_['params'][j],\n",
    "                           search_rf.cv_results_['params'][j]['rf_class__max_depth'],\n",
    "                           search_rf.cv_results_['params'][j]['rf_class__n_estimators'],\n",
    "                           search_rf.cv_results_['split'+str(i)+'_train_score'][j],\n",
    "                           search_rf.cv_results_['split'+str(i)+'_test_score'][j],\n",
    "                           over_fit])\n",
    "temp_df_rf = pd.DataFrame(temp_df_rf, columns=['parameters', 'max_depth', 'n_estimators', 'training', 'validation', 'overfit_%'])\n",
    "print(temp_df_rf)\n",
    "temp_df_rf.to_csv('../data/code_5a_rf_train_validate_recall.csv', na_rep='NaN', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998f797",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Severe overfitting with Random Forest Classifier.</span>  \n",
    "<br>  \n",
    "<br>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912699a",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 6: Explore Multinomial Naive Bayes</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec9a311",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : [0.50960961 0.51201201 0.51320785 0.5222115  0.53541399 0.57202917\n",
      " 0.6140444  0.77370764]\n",
      "Validation : [0.51309524 0.51309524 0.52142857 0.52142857 0.5297619  0.57142857\n",
      " 0.61309524 0.78214286]\n",
      "Overfit %: [ 0.68398013  0.21156263  1.60183066 -0.14992504 -1.05564681 -0.10499475\n",
      " -0.1545757   1.09023364]\n",
      "\n",
      "                      parameters   alpha  training  validation  overfit_%\n",
      "0       {'nb_class__alpha': 100}     100  0.495495    0.875000  76.590909\n",
      "1       {'nb_class__alpha': 100}     100  0.513514    0.500000  -2.631579\n",
      "2       {'nb_class__alpha': 100}     100  0.531532    0.375000 -29.449153\n",
      "3       {'nb_class__alpha': 100}     100  0.504505    0.500000  -0.892857\n",
      "4       {'nb_class__alpha': 100}     100  0.513514    0.250000 -51.315789\n",
      "..                           ...     ...       ...         ...        ...\n",
      "115  {'nb_class__alpha': 500000}  500000  0.765766    0.875000  14.264706\n",
      "116  {'nb_class__alpha': 500000}  500000  0.747748    0.750000   0.301205\n",
      "117  {'nb_class__alpha': 500000}  500000  0.756757    0.875000  15.625000\n",
      "118  {'nb_class__alpha': 500000}  500000  0.756757    0.625000 -17.410714\n",
      "119  {'nb_class__alpha': 500000}  500000  0.776786    0.857143  10.344828\n",
      "\n",
      "[120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------- make pipeline ----------\n",
    "\n",
    "pipe_line_nb = Pipeline([('knn_impute', KNNImputer(n_neighbors=5)),\n",
    "                         ('oversample_SMOTE', SMOTE(random_state=42)),\n",
    "#                         ('ss_scale', StandardScaler()),\n",
    "                         ('nb_class', MultinomialNB())])\n",
    "\n",
    "# ---------- tuning of hyperparameters ----------\n",
    "\n",
    "pipe_line_params_nb = {'nb_class__alpha': [100,500,1_000,5_000,10_000,50_000,100_000,500_000]}\n",
    "\n",
    "# ---------- instantiate gridsearchcv for recall in accordance to aim of modelling ----------\n",
    "\n",
    "search_nb = GridSearchCV(pipe_line_nb,\n",
    "                         param_grid=pipe_line_params_nb,\n",
    "                         cv=kfold_cv,\n",
    "                         return_train_score=True,\n",
    "                         scoring='recall')\n",
    "\n",
    "search_nb.fit(X_train, y_train)\n",
    "\n",
    "# ---------- quick overview of recall train score, test score and overfit ----------\n",
    "\n",
    "print('Training :', search_nb.cv_results_['mean_train_score'])\n",
    "print('Validation :', search_nb.cv_results_['mean_test_score'])\n",
    "print('Overfit %:', (search_nb.cv_results_['mean_test_score']-search_nb.cv_results_['mean_train_score'])/search_nb.cv_results_['mean_train_score']*100)\n",
    "print('')\n",
    "\n",
    "# ---------- details of recall train score and test score ----------\n",
    "\n",
    "temp_df_nb = []\n",
    "for j in range(len(search_nb.cv_results_['params'])):\n",
    "    for i in range(kfold_cv.n_splits):\n",
    "        over_fit = (search_nb.cv_results_['split'+str(i)+'_test_score'][j]-search_nb.cv_results_['split'+str(i)+'_train_score'][j])/search_nb.cv_results_['split'+str(i)+'_train_score'][j]*100\n",
    "        temp_df_nb.append([search_nb.cv_results_['params'][j],\n",
    "                           search_nb.cv_results_['params'][j]['nb_class__alpha'],\n",
    "                           search_nb.cv_results_['split'+str(i)+'_train_score'][j],\n",
    "                           search_nb.cv_results_['split'+str(i)+'_test_score'][j],\n",
    "                           over_fit])\n",
    "temp_df_nb = pd.DataFrame(temp_df_nb, columns=['parameters', 'alpha', 'training', 'validation', 'overfit_%'])\n",
    "print(temp_df_nb)\n",
    "temp_df_nb.to_csv('../data/code_5a_nb_train_validate_recall.csv', na_rep='NaN', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592a781",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Very small overfitting with Multinomial Naive Bayes.</span>  \n",
    "### <span style='color:green'>However, recall performance very low.</span>  \n",
    "<br>  \n",
    "<br>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc3068",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 7: Explore K Nearest Neighbours Classifier</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a9319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : [0.96458065 0.93456135 0.93037323 0.92436722 0.92917739 0.94057808\n",
      " 0.93937151 0.93576255]\n",
      "Validation : [0.81547619 0.81547619 0.85       0.85833333 0.88333333 0.89166667\n",
      " 0.9        0.9       ]\n",
      "Overfit %: [-15.45795691 -12.74235843  -8.63881588  -7.1436859   -4.93383274\n",
      "  -5.20014367  -4.19126126  -3.8217546 ]\n",
      "\n",
      "                        parameters  n_neighbours  training  validation  \\\n",
      "0    {'kn_class__n_neighbors': 10}            10  0.954955       0.875   \n",
      "1    {'kn_class__n_neighbors': 10}            10  0.963964       0.875   \n",
      "2    {'kn_class__n_neighbors': 10}            10  0.963964       1.000   \n",
      "3    {'kn_class__n_neighbors': 10}            10  0.954955       0.750   \n",
      "4    {'kn_class__n_neighbors': 10}            10  0.972973       0.750   \n",
      "..                             ...           ...       ...         ...   \n",
      "115  {'kn_class__n_neighbors': 80}            80  0.927928       0.875   \n",
      "116  {'kn_class__n_neighbors': 80}            80  0.936937       0.875   \n",
      "117  {'kn_class__n_neighbors': 80}            80  0.927928       0.875   \n",
      "118  {'kn_class__n_neighbors': 80}            80  0.936937       0.875   \n",
      "119  {'kn_class__n_neighbors': 80}            80  0.955357       1.000   \n",
      "\n",
      "     overfit_%  \n",
      "0    -8.372642  \n",
      "1    -9.228972  \n",
      "2     3.738318  \n",
      "3   -21.462264  \n",
      "4   -22.916667  \n",
      "..         ...  \n",
      "115  -5.703883  \n",
      "116  -6.610577  \n",
      "117  -5.703883  \n",
      "118  -6.610577  \n",
      "119   4.672897  \n",
      "\n",
      "[120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------- make pipeline ----------\n",
    "\n",
    "pipe_line_kn = Pipeline([('knn_impute', KNNImputer(n_neighbors=5)),\n",
    "                         ('oversample_SMOTE', SMOTE(random_state=42)),\n",
    "                         ('ss_scale', StandardScaler()),\n",
    "                         ('kn_class', KNeighborsClassifier())])\n",
    "\n",
    "# ---------- tuning of hyperparameters ----------\n",
    "\n",
    "pipe_line_params_kn = {'kn_class__n_neighbors': [10,20,30,40,50,60,70,80]}\n",
    "\n",
    "# ---------- instantiate gridsearchcv for recall in accordance to aim of modelling ----------\n",
    "\n",
    "search_kn = GridSearchCV(pipe_line_kn,\n",
    "                         param_grid=pipe_line_params_kn,\n",
    "                         cv=kfold_cv,\n",
    "                         return_train_score=True,\n",
    "                         scoring='recall')\n",
    "\n",
    "search_kn.fit(X_train, y_train)\n",
    "\n",
    "# ---------- quick overview of recall train score, test score and overfit ----------\n",
    "\n",
    "print('Training :', search_kn.cv_results_['mean_train_score'])\n",
    "print('Validation :', search_kn.cv_results_['mean_test_score'])\n",
    "print('Overfit %:', (search_kn.cv_results_['mean_test_score']-search_kn.cv_results_['mean_train_score'])/search_kn.cv_results_['mean_train_score']*100)\n",
    "print('')\n",
    "\n",
    "# ---------- details of recall train score and test score ----------\n",
    "\n",
    "temp_df_kn = []\n",
    "for j in range(len(search_kn.cv_results_['params'])):\n",
    "    for i in range(kfold_cv.n_splits):\n",
    "        over_fit = (search_kn.cv_results_['split'+str(i)+'_test_score'][j]-search_kn.cv_results_['split'+str(i)+'_train_score'][j])/search_kn.cv_results_['split'+str(i)+'_train_score'][j]*100\n",
    "        temp_df_kn.append([search_kn.cv_results_['params'][j],\n",
    "                           search_kn.cv_results_['params'][j]['kn_class__n_neighbors'],\n",
    "                           search_kn.cv_results_['split'+str(i)+'_train_score'][j],\n",
    "                           search_kn.cv_results_['split'+str(i)+'_test_score'][j],\n",
    "                           over_fit])\n",
    "temp_df_kn = pd.DataFrame(temp_df_kn, columns=['parameters', 'n_neighbours', 'training', 'validation', 'overfit_%'])\n",
    "print(temp_df_kn)\n",
    "temp_df_kn.to_csv('../data/code_5a_kn_train_validate_recall.csv', na_rep='NaN', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c8e2e",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Acceptable overfitting at some hyperparameters with K Nearest Neighbours Classifier.</span>  \n",
    "### <span style='color:green'>Recall performance higher than Multinomial Naive Bayes.</span>  \n",
    "<br>  \n",
    "<br>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc6747",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## <span style='color:blue'>Section 8: Explore Support Vector Classifier</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06c8b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : [0.05493887 0.11882239 0.0882293  0.14645538 0.18667417 0.21968576\n",
      " 0.92676963 0.81212462 0.6770592  0.59545796 0.60144788 0.63868511\n",
      " 0.95379665 0.97899507 0.99279816 0.99039575 1.         1.\n",
      " 0.98800408 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "Validation : [0.02857143 0.07738095 0.01785714 0.01785714 0.01785714 0.01785714\n",
      " 0.55595238 0.53928571 0.07619048 0.15238095 0.05119048 0.11071429\n",
      " 0.33571429 0.61309524 0.32738095 0.62261905 0.53690476 0.88214286\n",
      " 0.29285714 0.60595238 0.30119048 0.74761905 0.58690476 0.94166667\n",
      " 0.2952381  0.61428571 0.29285714 0.84047619 0.60357143 0.925\n",
      " 0.2952381  0.61428571 0.29285714 0.84880952 0.5952381  0.91666667]\n",
      "Overfit %: [-47.99414348 -34.87679393 -79.76052999 -87.80711069 -90.4340582\n",
      " -91.87150633 -40.01180392 -33.59569481 -88.74685168 -74.40945236\n",
      " -91.4887926  -82.6652785  -64.80232087 -37.37504314 -67.02441975\n",
      " -37.13431769 -46.30952381 -11.78571429 -70.35871105 -39.4047619\n",
      " -69.88095238 -25.23809524 -41.30952381  -5.83333333 -70.47619048\n",
      " -38.57142857 -70.71428571 -15.95238095 -39.64285714  -7.5\n",
      " -70.47619048 -38.57142857 -70.71428571 -15.11904762 -40.47619048\n",
      "  -8.33333333]\n",
      "\n",
      "                                         parameters        C  degree  \\\n",
      "0    {'svc_class__C': 0.01, 'svc_class__degree': 2}     0.01       2   \n",
      "1    {'svc_class__C': 0.01, 'svc_class__degree': 2}     0.01       2   \n",
      "2    {'svc_class__C': 0.01, 'svc_class__degree': 2}     0.01       2   \n",
      "3    {'svc_class__C': 0.01, 'svc_class__degree': 2}     0.01       2   \n",
      "4    {'svc_class__C': 0.01, 'svc_class__degree': 2}     0.01       2   \n",
      "..                                              ...      ...     ...   \n",
      "535  {'svc_class__C': 1000, 'svc_class__degree': 7}  1000.00       7   \n",
      "536  {'svc_class__C': 1000, 'svc_class__degree': 7}  1000.00       7   \n",
      "537  {'svc_class__C': 1000, 'svc_class__degree': 7}  1000.00       7   \n",
      "538  {'svc_class__C': 1000, 'svc_class__degree': 7}  1000.00       7   \n",
      "539  {'svc_class__C': 1000, 'svc_class__degree': 7}  1000.00       7   \n",
      "\n",
      "     training  validation  overfit_%  \n",
      "0    0.009009       0.000     -100.0  \n",
      "1    0.018018       0.000     -100.0  \n",
      "2    0.009009       0.000     -100.0  \n",
      "3    0.018018       0.000     -100.0  \n",
      "4    0.018018       0.000     -100.0  \n",
      "..        ...         ...        ...  \n",
      "535  1.000000       1.000        0.0  \n",
      "536  1.000000       0.750      -25.0  \n",
      "537  1.000000       0.875      -12.5  \n",
      "538  1.000000       0.875      -12.5  \n",
      "539  1.000000       1.000        0.0  \n",
      "\n",
      "[540 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------- make pipeline ----------\n",
    "\n",
    "pipe_line_scv = Pipeline([('knn_impute', KNNImputer(n_neighbors=5)),\n",
    "                          ('oversample_SMOTE', SMOTE(random_state=42)),\n",
    "                          ('ss_scale', StandardScaler()),\n",
    "                          ('svc_class', SVC(random_state=42, kernel='poly'))])\n",
    "\n",
    "# ---------- tuning of hyperparameters ----------\n",
    "\n",
    "pipe_line_params_scv = {'svc_class__C': [0.01,0.1,1,10,100,1_000],\n",
    "                        'svc_class__degree': [2,3,4,5,6,7]}\n",
    "\n",
    "# ---------- instantiate gridsearchcv for recall in accordance to aim of modelling ----------\n",
    "\n",
    "search_scv = GridSearchCV(pipe_line_scv,\n",
    "                          param_grid=pipe_line_params_scv,\n",
    "                          cv=kfold_cv,\n",
    "                          return_train_score=True,\n",
    "                          scoring='recall')\n",
    "\n",
    "search_scv.fit(X_train, y_train)\n",
    "\n",
    "# ---------- quick overview of recall train score, test score and overfit ----------\n",
    "\n",
    "print('Training :', search_scv.cv_results_['mean_train_score'])\n",
    "print('Validation :', search_scv.cv_results_['mean_test_score'])\n",
    "print('Overfit %:', (search_scv.cv_results_['mean_test_score']-search_scv.cv_results_['mean_train_score'])/search_scv.cv_results_['mean_train_score']*100)\n",
    "print('')\n",
    "\n",
    "# ---------- details of recall train score and test score ----------\n",
    "\n",
    "temp_df_scv = []\n",
    "for j in range(len(search_scv.cv_results_['params'])):\n",
    "    for i in range(kfold_cv.n_splits):\n",
    "        over_fit = (search_scv.cv_results_['split'+str(i)+'_test_score'][j]-search_scv.cv_results_['split'+str(i)+'_train_score'][j])/search_scv.cv_results_['split'+str(i)+'_train_score'][j]*100\n",
    "        temp_df_scv.append([search_scv.cv_results_['params'][j],\n",
    "                            search_scv.cv_results_['params'][j]['svc_class__C'],\n",
    "                            search_scv.cv_results_['params'][j]['svc_class__degree'],\n",
    "                            search_scv.cv_results_['split'+str(i)+'_train_score'][j],\n",
    "                            search_scv.cv_results_['split'+str(i)+'_test_score'][j],\n",
    "                            over_fit])\n",
    "temp_df_scv = pd.DataFrame(temp_df_scv, columns=['parameters', 'C', 'degree', 'training', 'validation', 'overfit_%'])\n",
    "print(temp_df_scv)\n",
    "temp_df_scv.to_csv('../data/code_5a_scv_train_validate_recall.csv', na_rep='NaN', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e7157",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Severe overfitting with Support Vector Classifier.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6bc85",
   "metadata": {},
   "source": [
    "### <span style='color:green'>Will perform parameters and hyperparameters search on K Nearest Neighbours to finalise predictive model because it has good balance between overfit and recall.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2825b",
   "metadata": {},
   "source": [
    "3 Jan 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c29a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
