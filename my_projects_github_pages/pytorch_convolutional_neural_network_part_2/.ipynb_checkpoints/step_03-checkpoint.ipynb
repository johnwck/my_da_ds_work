{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc41c4f-e450-4ac8-83f5-64e4602e568f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Objective: To train simple CNN model and use trained model for classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c1dac-61c6-4054-90c0-71e9fb6fd18b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 1: Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1062a02-6bf5-44d0-9f93-197e2dae268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chi_k\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\chi_k\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fd692c-9977-426d-b3fa-0f2c63802bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x248d0b76250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7c2397-77b7-4c2b-ade7-15002f302a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85baa78b-7a27-4158-8cef-414c5cf0b7b8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 2: Read and transform**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec9ab7b-428e-498c-9a3e-8801c3926cb6",
   "metadata": {},
   "source": [
    "**Train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed38378-5bed-422d-8f4d-ece67bc7afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1 = pd.read_pickle('./data/cifar-10-batches-py/data_batch_1')\n",
    "pf2 = pd.read_pickle('./data/cifar-10-batches-py/data_batch_2')\n",
    "pf3 = pd.read_pickle('./data/cifar-10-batches-py/data_batch_3')\n",
    "pf4 = pd.read_pickle('./data/cifar-10-batches-py/data_batch_4')\n",
    "pf5 = pd.read_pickle('./data/cifar-10-batches-py/data_batch_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa1a486-c3fa-4948-a93b-ed2d05874e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pf1['batch_label']\n",
    "del pf2['batch_label']\n",
    "del pf3['batch_label']\n",
    "del pf4['batch_label']\n",
    "del pf5['batch_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6818ac23-74fd-45d1-a1c4-b45a31034ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1['data'] = list(pf1['data'])\n",
    "pf2['data'] = list(pf2['data'])\n",
    "pf3['data'] = list(pf3['data'])\n",
    "pf4['data'] = list(pf4['data'])\n",
    "pf5['data'] = list(pf5['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200bf004-2937-4e47-858a-ed5de4af0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1_df = pd.DataFrame(pf1)\n",
    "pf2_df = pd.DataFrame(pf2)\n",
    "pf3_df = pd.DataFrame(pf3)\n",
    "pf4_df = pd.DataFrame(pf4)\n",
    "pf5_df = pd.DataFrame(pf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87350b6b-0215-40dc-92d5-d8446a85f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([pf1_df,\n",
    "                      pf2_df,\n",
    "                      pf3_df,\n",
    "                      pf4_df,\n",
    "                      pf5_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57c6a3-d5eb-47c6-9136-f5816f0105ad",
   "metadata": {},
   "source": [
    "**Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c961d09b-d9a3-4e59-88e6-2659aecd75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_pickle('./data/cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3776d7ab-aeef-451f-aa2d-b7e36c970252",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pf['batch_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea875cc-acad-45ea-a9b4-833c00285ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['data'] = list(pf['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaaffcfb-e2fc-4fdd-a1e7-1d247fc81cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ae21f-dee6-4859-9721-e1bfb427f12b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 3: Transform to X_train and y_train in tensor form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420477d5-ef89-47d0-a866-9fbe6026db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['data'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1d1c59-45f9-49e8-8745-83a47d9fbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecd04b04-70af-4f1d-a72e-53e735e264f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape((-1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd71d2d3-a72c-4be7-a35e-bdc122e0ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3906342-e8bb-4243-9e87-fd6a9f1e3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cad3fb9-0256-4bd2-a9b6-5a807ae70296",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c2c3f-9b71-4755-b475-2a46518db831",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 4: Transform to X_test and y_test in tensor form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a21cfdb9-43b0-436c-949c-f608be2e10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['data'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b64a82-6ae5-43cd-ad0f-5800533ea862",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78b6a46c-f574-4ff2-86f8-03862230517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test, dtype=torch.float32).reshape((-1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8aa0072-f058-4e4a-b537-93ebb4cef0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223a1926-3639-45a3-ae90-8e12929f8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4032925f-c05d-4cf3-9897-3fb95676dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707693-919c-4e59-9afd-43aee5288613",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 5: Push X_train, y_train, X_test, and y_test to GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a27986-3a24-4441-891c-c2c0beba5722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d5fd445-df43-43a9-a8d1-47ea9ae6e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5db54da9-5e69-4c08-a990-1b17f52312b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 59.,  43.,  50.,  ..., 158., 152., 148.],\n",
       "          [ 16.,   0.,  18.,  ..., 123., 119., 122.],\n",
       "          [ 25.,  16.,  49.,  ..., 118., 120., 109.],\n",
       "          ...,\n",
       "          [208., 201., 198.,  ..., 160.,  56.,  53.],\n",
       "          [180., 173., 186.,  ..., 184.,  97.,  83.],\n",
       "          [177., 168., 179.,  ..., 216., 151., 123.]],\n",
       "\n",
       "         [[ 62.,  46.,  48.,  ..., 132., 125., 124.],\n",
       "          [ 20.,   0.,   8.,  ...,  88.,  83.,  87.],\n",
       "          [ 24.,   7.,  27.,  ...,  84.,  84.,  73.],\n",
       "          ...,\n",
       "          [170., 153., 161.,  ..., 133.,  31.,  34.],\n",
       "          [139., 123., 144.,  ..., 148.,  62.,  53.],\n",
       "          [144., 129., 142.,  ..., 184., 118.,  92.]],\n",
       "\n",
       "         [[ 63.,  45.,  43.,  ..., 108., 102., 103.],\n",
       "          [ 20.,   0.,   0.,  ...,  55.,  50.,  57.],\n",
       "          [ 21.,   0.,   8.,  ...,  50.,  50.,  42.],\n",
       "          ...,\n",
       "          [ 96.,  34.,  26.,  ...,  70.,   7.,  20.],\n",
       "          [ 96.,  42.,  30.,  ...,  94.,  34.,  34.],\n",
       "          [116.,  94.,  87.,  ..., 140.,  84.,  72.]]],\n",
       "\n",
       "\n",
       "        [[[154., 126., 105.,  ...,  91.,  87.,  79.],\n",
       "          [140., 145., 125.,  ...,  96.,  77.,  71.],\n",
       "          [140., 139., 115.,  ...,  79.,  68.,  67.],\n",
       "          ...,\n",
       "          [175., 156., 154.,  ...,  42.,  61.,  93.],\n",
       "          [165., 156., 159.,  ..., 103., 123., 131.],\n",
       "          [163., 158., 163.,  ..., 143., 143., 143.]],\n",
       "\n",
       "         [[177., 137., 104.,  ...,  95.,  90.,  81.],\n",
       "          [160., 153., 125.,  ...,  99.,  80.,  73.],\n",
       "          [155., 146., 115.,  ...,  82.,  70.,  69.],\n",
       "          ...,\n",
       "          [167., 154., 160.,  ...,  34.,  53.,  83.],\n",
       "          [154., 152., 161.,  ...,  93., 114., 121.],\n",
       "          [148., 148., 156.,  ..., 133., 134., 133.]],\n",
       "\n",
       "         [[187., 136.,  95.,  ...,  71.,  71.,  70.],\n",
       "          [169., 154., 118.,  ...,  78.,  62.,  61.],\n",
       "          [164., 149., 112.,  ...,  64.,  55.,  55.],\n",
       "          ...,\n",
       "          [166., 160., 170.,  ...,  36.,  57.,  91.],\n",
       "          [128., 130., 142.,  ...,  96., 120., 131.],\n",
       "          [120., 122., 133.,  ..., 139., 142., 144.]]],\n",
       "\n",
       "\n",
       "        [[[255., 253., 253.,  ..., 253., 253., 253.],\n",
       "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "          [255., 254., 254.,  ..., 254., 254., 254.],\n",
       "          ...,\n",
       "          [113., 111., 105.,  ...,  72.,  72.,  72.],\n",
       "          [111., 104.,  99.,  ...,  68.,  70.,  78.],\n",
       "          [106.,  99.,  95.,  ...,  78.,  79.,  80.]],\n",
       "\n",
       "         [[255., 253., 253.,  ..., 253., 253., 253.],\n",
       "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "          [255., 254., 254.,  ..., 254., 254., 254.],\n",
       "          ...,\n",
       "          [120., 118., 112.,  ...,  81.,  80.,  80.],\n",
       "          [118., 111., 106.,  ...,  75.,  76.,  84.],\n",
       "          [113., 106., 102.,  ...,  85.,  85.,  86.]],\n",
       "\n",
       "         [[255., 253., 253.,  ..., 253., 253., 253.],\n",
       "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
       "          [255., 254., 254.,  ..., 254., 254., 254.],\n",
       "          ...,\n",
       "          [112., 111., 106.,  ...,  80.,  79.,  79.],\n",
       "          [110., 104.,  98.,  ...,  73.,  75.,  82.],\n",
       "          [105.,  98.,  94.,  ...,  83.,  83.,  84.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "569f09fa-9695-4c40-b308-bb126e07755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d09c68-eaf8-4526-88ba-a86d3ca42177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "430a81d1-92cc-421e-98cf-3a9d058678d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a374a06-69a2-4eb5-ba83-1aabf9b97cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[158., 159., 165.,  ..., 137., 126., 116.],\n",
       "          [152., 151., 159.,  ..., 136., 125., 119.],\n",
       "          [151., 151., 158.,  ..., 139., 130., 120.],\n",
       "          ...,\n",
       "          [ 68.,  42.,  31.,  ...,  38.,  13.,  40.],\n",
       "          [ 61.,  49.,  35.,  ...,  26.,  29.,  20.],\n",
       "          [ 54.,  56.,  45.,  ...,  24.,  34.,  21.]],\n",
       "\n",
       "         [[112., 111., 116.,  ...,  95.,  91.,  85.],\n",
       "          [112., 110., 114.,  ...,  95.,  91.,  88.],\n",
       "          [110., 109., 111.,  ...,  98.,  95.,  89.],\n",
       "          ...,\n",
       "          [124., 100.,  88.,  ...,  97.,  64.,  85.],\n",
       "          [116., 102.,  85.,  ...,  82.,  82.,  64.],\n",
       "          [107., 105.,  89.,  ...,  77.,  84.,  67.]],\n",
       "\n",
       "         [[ 49.,  47.,  51.,  ...,  36.,  36.,  33.],\n",
       "          [ 51.,  40.,  45.,  ...,  31.,  32.,  34.],\n",
       "          [ 47.,  33.,  36.,  ...,  34.,  34.,  33.],\n",
       "          ...,\n",
       "          [177., 148., 137.,  ..., 146., 108., 127.],\n",
       "          [168., 148., 132.,  ..., 130., 126., 107.],\n",
       "          [160., 149., 132.,  ..., 124., 129., 110.]]],\n",
       "\n",
       "\n",
       "        [[[235., 231., 232.,  ..., 233., 233., 232.],\n",
       "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
       "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
       "          ...,\n",
       "          [ 87.,  43.,  19.,  ..., 169., 182., 188.],\n",
       "          [ 82.,  46.,  36.,  ..., 174., 185., 187.],\n",
       "          [ 85.,  62.,  58.,  ..., 168., 180., 186.]],\n",
       "\n",
       "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
       "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
       "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
       "          ...,\n",
       "          [ 99.,  51.,  23.,  ..., 184., 197., 202.],\n",
       "          [ 96.,  57.,  44.,  ..., 189., 200., 202.],\n",
       "          [101.,  75.,  67.,  ..., 183., 195., 200.]],\n",
       "\n",
       "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
       "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
       "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
       "          ...,\n",
       "          [ 89.,  37.,  11.,  ..., 179., 193., 201.],\n",
       "          [ 82.,  36.,  22.,  ..., 183., 196., 200.],\n",
       "          [ 83.,  48.,  38.,  ..., 178., 191., 199.]]],\n",
       "\n",
       "\n",
       "        [[[158., 158., 139.,  ..., 228., 237., 238.],\n",
       "          [170., 172., 151.,  ..., 232., 246., 246.],\n",
       "          [174., 176., 157.,  ..., 230., 250., 245.],\n",
       "          ...,\n",
       "          [ 31.,  30.,  26.,  ...,  37.,   9.,   4.],\n",
       "          [ 23.,  27.,  25.,  ...,  19.,   4.,   5.],\n",
       "          [ 28.,  30.,  32.,  ...,   5.,   4.,   7.]],\n",
       "\n",
       "         [[190., 187., 166.,  ..., 231., 239., 241.],\n",
       "          [200., 199., 176.,  ..., 232., 246., 247.],\n",
       "          [201., 200., 179.,  ..., 229., 249., 244.],\n",
       "          ...,\n",
       "          [ 40.,  39.,  35.,  ...,  40.,  13.,   7.],\n",
       "          [ 34.,  38.,  36.,  ...,  20.,   6.,   7.],\n",
       "          [ 41.,  43.,  45.,  ...,   6.,   5.,   8.]],\n",
       "\n",
       "         [[222., 218., 194.,  ..., 234., 243., 246.],\n",
       "          [229., 226., 201.,  ..., 236., 250., 251.],\n",
       "          [225., 222., 199.,  ..., 232., 251., 247.],\n",
       "          ...,\n",
       "          [ 45.,  44.,  40.,  ...,  46.,  14.,   5.],\n",
       "          [ 39.,  43.,  41.,  ...,  24.,   3.,   3.],\n",
       "          [ 47.,  50.,  52.,  ...,   8.,   3.,   7.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aa811d7-1e0b-453a-ad53-a132a013fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52bdb8d6-6be2-465e-a476-8f38723895fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a78e77-729a-4e8c-a071-875a5b85390b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 6: Set up custom dataset (train and test) using torch.utils.data.Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d7ea0d-9af6-4743-817b-cc20cab6662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y[idx]\n",
    "        X = self.X[idx]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f481e613-bb7b-4fca-859d-9b943241d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d18324f-3437-406d-8f74-0d0d8181703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a787fc-cfee-4d2a-9d3e-a1aaa4df4b17",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 7: Set up custom dataloader (train and test) using torch.utils.data.DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e663c73-ea41-4171-96e5-6f507677d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22adc390-a7ba-4f66-acd1-00fa6eccab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f59ee-7fd6-4d37-ad05-a1efe459b1ba",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 8: Set up Convolutional Neural Network (CNN) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5a3b476-10a5-460b-bfa8-4883a0df7e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn__model(\n",
      "  (conv1): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class cnn__model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=9, kernel_size=(3,3), padding=1, stride=1)   # input = 3 x 32 x 32   output = 9 x 32 x 32\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))                                                     # input = 9 x 32 x 32   output = 9 x 16 x 16\n",
    "        self.fc1 = nn.Linear(9*16*16, 100)                                                              # input = 9 x 16 x 16   output = 100\n",
    "        self.fc2 = nn.Linear(100, 10)                                                                   # input = 100           output = 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nnf.relu(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1)                                                                         # input = 9 x 16 x 16   output = 9 x 16 x 16\n",
    "        x = nnf.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = cnn__model().to(device)\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b8d25b1-d890-4468-a9a3-cdc3768c2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cnn_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6617c3-25f5-4631-ba12-0377ae1d43dd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 9: Train CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e9f562d-ddac-4109-9042-06ab38331308",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.000001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3847a5d-dea6-45ba-8bc2-c5f88bce1eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5459.909855127335\n",
      "Epoch 2, Loss: 4387.320788502693\n",
      "Epoch 3, Loss: 4192.974305033684\n",
      "Epoch 4, Loss: 4078.79383790493\n",
      "Epoch 5, Loss: 3992.896406173706\n",
      "Epoch 6, Loss: 3922.212301015854\n",
      "Epoch 7, Loss: 3862.294492483139\n",
      "Epoch 8, Loss: 3809.947520852089\n",
      "Epoch 9, Loss: 3763.2677326202393\n",
      "Epoch 10, Loss: 3721.355789065361\n",
      "Epoch 11, Loss: 3683.0649741888046\n",
      "Epoch 12, Loss: 3647.940400004387\n",
      "Epoch 13, Loss: 3615.2455648183823\n",
      "Epoch 14, Loss: 3584.7410439252853\n",
      "Epoch 15, Loss: 3555.881305336952\n",
      "Epoch 16, Loss: 3528.643193244934\n",
      "Epoch 17, Loss: 3502.5552400946617\n",
      "Epoch 18, Loss: 3477.551467061043\n",
      "Epoch 19, Loss: 3453.6456122994423\n",
      "Epoch 20, Loss: 3430.5904825925827\n",
      "Epoch 21, Loss: 3408.463115334511\n",
      "Epoch 22, Loss: 3387.238999903202\n",
      "Epoch 23, Loss: 3366.7186497449875\n",
      "Epoch 24, Loss: 3346.9531366825104\n",
      "Epoch 25, Loss: 3327.974506020546\n",
      "Epoch 26, Loss: 3309.731041133404\n",
      "Epoch 27, Loss: 3292.022572696209\n",
      "Epoch 28, Loss: 3274.816314160824\n",
      "Epoch 29, Loss: 3258.0716821551323\n",
      "Epoch 30, Loss: 3241.833878159523\n",
      "Epoch 31, Loss: 3226.2129630446434\n",
      "Epoch 32, Loss: 3210.978380918503\n",
      "Epoch 33, Loss: 3196.40389752388\n",
      "Epoch 34, Loss: 3182.384741783142\n",
      "Epoch 35, Loss: 3168.7032411694527\n",
      "Epoch 36, Loss: 3155.3907713890076\n",
      "Epoch 37, Loss: 3142.5786601901054\n",
      "Epoch 38, Loss: 3130.231034576893\n",
      "Epoch 39, Loss: 3118.1684897542\n",
      "Epoch 40, Loss: 3106.404958665371\n",
      "Epoch 41, Loss: 3094.9466723799706\n",
      "Epoch 42, Loss: 3083.6969077587128\n",
      "Epoch 43, Loss: 3072.6637932658195\n",
      "Epoch 44, Loss: 3061.817497551441\n",
      "Epoch 45, Loss: 3051.2332694530487\n",
      "Epoch 46, Loss: 3040.8900703191757\n",
      "Epoch 47, Loss: 3030.7219824790955\n",
      "Epoch 48, Loss: 3020.6666699051857\n",
      "Epoch 49, Loss: 3010.8934923410416\n",
      "Epoch 50, Loss: 3001.247023642063\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss = running_loss + loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss}\")\n",
    "\n",
    "print()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a9145-5dfe-4bf4-af7e-6f463661e048",
   "metadata": {},
   "source": [
    "**Save trained model for use later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16301ddb-8cbb-410c-bc4d-17fa1d10d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model, 'trained_cnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5a15c-77eb-4ba4-9e61-b151b335d15c",
   "metadata": {},
   "source": [
    "**Display trained model at high level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d98305fe-29b9-4f79-97e7-1e2b13519618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([9, 3, 3, 3])\n",
      "conv1.bias \t torch.Size([9])\n",
      "fc1.weight \t torch.Size([100, 2304])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([10, 100])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in cnn_model.state_dict():\n",
    "    print(i, \"\\t\", cnn_model.state_dict()[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f5cd9-d795-4901-ad16-36decf1b5136",
   "metadata": {},
   "source": [
    "**Display trained model at low level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b673bcb0-b758-4692-b6ed-daf5b326101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t tensor([[[[ 0.1181,  0.1192, -0.0612],\n",
      "          [ 0.1412, -0.0890, -0.0057],\n",
      "          [-0.0852,  0.0963,  0.1388]],\n",
      "\n",
      "         [[-0.1616,  0.1376,  0.0259],\n",
      "          [ 0.1096, -0.0147,  0.0501],\n",
      "          [-0.0273,  0.1266, -0.0075]],\n",
      "\n",
      "         [[-0.0902,  0.0423, -0.0808],\n",
      "          [-0.0276, -0.0875,  0.1123],\n",
      "          [-0.1353, -0.0887, -0.0702]]],\n",
      "\n",
      "\n",
      "        [[[-0.1148,  0.0483, -0.1807],\n",
      "          [ 0.1795, -0.1656,  0.1354],\n",
      "          [ 0.0133, -0.0787,  0.0932]],\n",
      "\n",
      "         [[ 0.0189,  0.1672,  0.0135],\n",
      "          [-0.0602,  0.0392, -0.0724],\n",
      "          [ 0.0563,  0.1437,  0.0759]],\n",
      "\n",
      "         [[-0.0980,  0.1196,  0.0250],\n",
      "          [ 0.0991, -0.1257, -0.2068],\n",
      "          [-0.0929, -0.1680,  0.1281]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0466,  0.0819,  0.0629],\n",
      "          [-0.0106,  0.1462, -0.1405],\n",
      "          [ 0.0107, -0.1419,  0.0471]],\n",
      "\n",
      "         [[-0.0683,  0.0642, -0.0404],\n",
      "          [ 0.1599, -0.1129, -0.1178],\n",
      "          [-0.1096,  0.1680,  0.0545]],\n",
      "\n",
      "         [[ 0.1839, -0.1529, -0.1875],\n",
      "          [-0.1477, -0.1254,  0.0807],\n",
      "          [ 0.0760,  0.1575, -0.1032]]],\n",
      "\n",
      "\n",
      "        [[[-0.1326,  0.1001, -0.0805],\n",
      "          [ 0.1147, -0.0477,  0.1077],\n",
      "          [-0.1497, -0.0974,  0.0584]],\n",
      "\n",
      "         [[ 0.0393, -0.0507,  0.1123],\n",
      "          [ 0.1289, -0.1412, -0.1047],\n",
      "          [ 0.1761, -0.0651, -0.0684]],\n",
      "\n",
      "         [[-0.1864, -0.1106,  0.0470],\n",
      "          [-0.0259, -0.1401,  0.0037],\n",
      "          [-0.1315, -0.1633, -0.1061]]],\n",
      "\n",
      "\n",
      "        [[[-0.1685, -0.1229,  0.1911],\n",
      "          [ 0.0362,  0.0595, -0.1796],\n",
      "          [-0.1264, -0.0637,  0.0302]],\n",
      "\n",
      "         [[-0.1695, -0.0830, -0.1162],\n",
      "          [ 0.0003, -0.0709, -0.0129],\n",
      "          [-0.1305, -0.1315, -0.1119]],\n",
      "\n",
      "         [[-0.0659, -0.1525,  0.1597],\n",
      "          [-0.0383,  0.1661,  0.0602],\n",
      "          [-0.1629,  0.1337, -0.0526]]],\n",
      "\n",
      "\n",
      "        [[[-0.0644, -0.1571, -0.1687],\n",
      "          [ 0.0357, -0.0765,  0.0847],\n",
      "          [-0.1559,  0.1165, -0.1290]],\n",
      "\n",
      "         [[-0.0235,  0.0436,  0.1200],\n",
      "          [ 0.1408,  0.1467, -0.1401],\n",
      "          [ 0.0535, -0.1043, -0.0066]],\n",
      "\n",
      "         [[-0.1290,  0.1847, -0.1179],\n",
      "          [ 0.0981,  0.0482,  0.0820],\n",
      "          [-0.0918,  0.1615,  0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0416, -0.1551,  0.0942],\n",
      "          [-0.0243, -0.0832,  0.1736],\n",
      "          [ 0.0378, -0.1031, -0.0916]],\n",
      "\n",
      "         [[-0.0024,  0.1120, -0.0490],\n",
      "          [-0.1149, -0.0702, -0.1465],\n",
      "          [ 0.0568,  0.1459, -0.1816]],\n",
      "\n",
      "         [[ 0.0485,  0.1011,  0.0289],\n",
      "          [-0.0766,  0.0939,  0.0932],\n",
      "          [ 0.0507, -0.0465, -0.0636]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0269, -0.0357, -0.0327],\n",
      "          [ 0.1180,  0.1560,  0.0006],\n",
      "          [-0.0495, -0.0111, -0.0032]],\n",
      "\n",
      "         [[ 0.0483,  0.0460, -0.1601],\n",
      "          [-0.0772,  0.1510,  0.0894],\n",
      "          [-0.0154, -0.1314, -0.1128]],\n",
      "\n",
      "         [[-0.1542, -0.0615,  0.0867],\n",
      "          [ 0.1324,  0.0844, -0.1509],\n",
      "          [-0.1058, -0.0388,  0.1920]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0324, -0.0443,  0.0806],\n",
      "          [-0.0698, -0.1192,  0.1409],\n",
      "          [-0.0847, -0.0304, -0.1831]],\n",
      "\n",
      "         [[ 0.1292,  0.1471,  0.0669],\n",
      "          [-0.1336, -0.1874, -0.1587],\n",
      "          [ 0.1447,  0.0987,  0.1686]],\n",
      "\n",
      "         [[ 0.1018,  0.0506, -0.0039],\n",
      "          [-0.1439, -0.1602, -0.1797],\n",
      "          [ 0.0811, -0.0870, -0.0303]]]], device='cuda:0')\n",
      "conv1.bias \t tensor([-0.1095, -0.0339, -0.1356, -0.1257,  0.0638, -0.0573,  0.1191, -0.0626, -0.1412], device='cuda:0')\n",
      "fc1.weight \t tensor([[-0.0041, -0.0106, -0.0069,  ..., -0.0077,  0.0036, -0.0145],\n",
      "        [ 0.0007,  0.0090,  0.0118,  ..., -0.0092, -0.0051,  0.0072],\n",
      "        [-0.0033,  0.0068,  0.0036,  ...,  0.0154,  0.0029, -0.0016],\n",
      "        ...,\n",
      "        [-0.0041, -0.0076, -0.0009,  ..., -0.0064, -0.0139,  0.0184],\n",
      "        [-0.0147,  0.0104,  0.0048,  ..., -0.0057, -0.0204, -0.0166],\n",
      "        [ 0.0180,  0.0159, -0.0096,  ...,  0.0117, -0.0114, -0.0046]], device='cuda:0')\n",
      "fc1.bias \t tensor([-0.0051,  0.0119,  0.0098,  0.0161,  0.0202,  0.0080,  0.0032, -0.0131, -0.0117,  0.0045,  0.0026,  0.0004,  0.0031,  0.0055,  0.0142,  0.0031, -0.0056,  0.0033,  0.0201,  0.0128,  0.0026,  0.0123,  0.0052,  0.0080, -0.0077,  0.0127, -0.0121, -0.0152, -0.0154, -0.0165, -0.0116,  0.0057,\n",
      "         0.0192, -0.0003, -0.0057,  0.0066,  0.0200,  0.0029,  0.0125, -0.0110, -0.0005, -0.0030,  0.0041,  0.0190,  0.0141, -0.0008,  0.0068, -0.0184,  0.0002, -0.0031,  0.0144,  0.0046, -0.0057, -0.0125, -0.0104,  0.0045,  0.0149,  0.0179, -0.0163,  0.0011,  0.0146,  0.0159,  0.0122, -0.0159,\n",
      "         0.0118,  0.0168, -0.0161, -0.0008,  0.0096, -0.0181, -0.0168,  0.0175,  0.0206, -0.0149,  0.0039, -0.0142, -0.0164, -0.0155,  0.0028, -0.0027,  0.0026, -0.0050,  0.0168, -0.0028,  0.0127, -0.0165, -0.0171,  0.0171, -0.0046,  0.0019, -0.0050, -0.0105, -0.0093,  0.0032,  0.0132, -0.0060,\n",
      "         0.0143,  0.0176,  0.0108, -0.0119], device='cuda:0')\n",
      "fc2.weight \t tensor([[ 3.5779e-02,  5.9280e-02,  1.1996e-04,  1.7265e-02, -8.1061e-02, -9.4740e-02, -7.9394e-02, -1.5369e-02, -2.4553e-02,  6.0809e-03,  6.6896e-02, -1.1984e-02, -4.7694e-02, -5.9700e-02, -7.6712e-02, -7.3467e-02,  2.5620e-02,  5.9196e-02, -7.8656e-03,  5.6720e-02,  7.8295e-02, -1.8023e-02,\n",
      "         -9.6957e-02,  7.0610e-02, -2.3190e-02, -3.0406e-02,  6.6599e-02, -2.9039e-02, -4.9890e-02, -2.8228e-02, -8.3863e-02, -4.2364e-02, -7.5913e-02,  3.7087e-02, -8.4170e-02, -1.6101e-02,  5.6960e-02, -5.7450e-02, -5.5289e-02, -7.8649e-02,  3.0220e-02,  6.8565e-02,  5.0409e-03, -7.5921e-02,\n",
      "          4.9805e-03, -2.9019e-02, -5.5263e-02, -6.5321e-02,  3.8554e-02,  5.1663e-02,  2.8580e-02, -4.8667e-02,  2.1511e-02,  5.2556e-02, -2.9059e-02,  6.4164e-04,  7.8593e-02,  8.8472e-02,  5.7926e-02,  7.2088e-02, -2.9381e-02,  7.9703e-02, -8.3166e-02, -3.9661e-02,  7.3791e-03,  9.0770e-02,\n",
      "         -4.0084e-02,  4.6789e-02, -9.3442e-02, -2.3375e-02,  4.9196e-02, -4.1504e-02,  4.1534e-02,  6.8383e-02, -8.0973e-03, -9.0187e-03,  1.6207e-02, -6.6258e-02, -3.9816e-03, -6.6657e-02,  8.8363e-02,  6.9768e-02, -1.6596e-02, -2.8855e-02, -9.7722e-02,  6.1574e-03, -7.4734e-02,  2.0418e-02,\n",
      "          8.8337e-02,  8.6597e-02,  1.7059e-02,  4.0731e-02, -7.7438e-02,  1.4227e-02, -7.3211e-02, -9.3185e-02, -8.5766e-02,  1.0069e-02,  4.1290e-02,  1.0257e-01],\n",
      "        [ 5.9014e-02, -6.2501e-02, -6.6913e-02,  4.1338e-02, -7.0164e-02,  8.3885e-02, -8.7379e-02,  4.3759e-02,  6.3228e-02, -8.9138e-02,  2.0196e-02,  4.2954e-02,  3.0711e-02,  7.3532e-02,  5.2300e-02, -1.0683e-02, -4.8840e-03, -3.5624e-02,  3.0175e-03, -9.2366e-03,  1.1167e-03, -4.4800e-02,\n",
      "          9.8075e-02, -9.5887e-03, -3.3865e-02, -6.2858e-02, -7.5750e-02,  9.6867e-02,  8.1118e-02, -8.2503e-02, -7.0029e-03, -8.1120e-02, -3.3118e-02,  8.1840e-02,  8.9008e-02,  7.5473e-02,  5.7151e-02,  3.3107e-02,  1.1944e-03,  2.8827e-02,  2.2817e-02,  8.9806e-02,  3.5622e-02, -7.0584e-02,\n",
      "         -9.9608e-03, -2.7105e-02,  1.9299e-02, -5.9259e-02, -4.9642e-02, -2.6446e-02,  5.8916e-02,  4.4819e-02, -6.6513e-02,  4.7425e-04, -3.0804e-02,  2.0976e-02, -8.1720e-02, -5.3530e-02,  4.0898e-02,  6.8111e-02, -6.0111e-03,  4.2906e-02,  6.5850e-02, -2.6804e-03, -1.2530e-02,  6.9658e-02,\n",
      "          5.0477e-02,  9.7111e-02, -9.6204e-02, -3.2177e-02, -2.0089e-03,  5.4973e-02,  7.0434e-02, -6.5039e-02, -2.2999e-02,  9.8244e-02, -8.9666e-02, -3.7996e-02,  3.4870e-02, -8.3295e-03,  6.9529e-02, -6.4993e-02,  4.4575e-02, -8.8523e-03, -4.5565e-02,  6.8869e-02, -6.6131e-02, -1.9682e-02,\n",
      "          9.4415e-02,  6.8675e-02, -9.6754e-02, -1.7897e-02,  3.6081e-02,  9.9008e-03,  6.7267e-02, -5.5221e-03, -2.9967e-02, -4.1571e-02, -5.9243e-02,  2.4768e-02],\n",
      "        [-3.6090e-02,  3.1826e-02,  6.2617e-02, -5.0676e-02, -1.0134e-02, -1.1498e-02,  4.1045e-02, -8.6132e-02, -4.9620e-04,  2.4197e-02, -7.3753e-02,  1.6843e-02,  3.8099e-02, -4.2072e-02,  1.8995e-02,  6.7812e-02,  4.2518e-02, -3.3000e-02,  8.6936e-02, -1.9972e-02,  7.0319e-02,  6.7164e-02,\n",
      "          7.4893e-02, -2.7036e-02,  4.4622e-02, -4.4079e-02,  5.6515e-03, -8.6710e-02, -3.8471e-03, -9.2176e-02, -9.5653e-02,  3.3170e-02, -4.4859e-02, -5.1265e-02,  5.9069e-03,  4.6325e-02,  4.5519e-02,  6.2765e-02,  2.6001e-02,  4.3239e-02,  5.4688e-02, -3.1698e-02, -8.8132e-02,  1.8408e-02,\n",
      "         -6.0245e-02, -2.9017e-02,  4.9443e-02, -5.0673e-02,  8.7065e-02, -6.0653e-02,  9.2462e-02, -8.7838e-02,  2.4208e-02, -2.7319e-02, -2.2739e-02,  1.2330e-03,  3.1136e-03,  9.4994e-02, -4.4782e-02,  1.0384e-02, -8.7042e-02,  7.8410e-02, -2.8221e-02, -9.1177e-02,  9.3757e-02,  5.5299e-02,\n",
      "         -9.3788e-02,  1.3677e-02, -5.6385e-02, -5.1249e-02,  8.7548e-02,  8.4169e-02,  5.8425e-02,  5.9651e-02, -6.7202e-02,  3.5986e-02, -5.8437e-02, -2.7636e-02, -2.1439e-02, -8.1892e-02,  4.4452e-02, -4.8572e-02,  1.3550e-02,  8.3929e-02,  4.7981e-02, -5.8921e-02, -6.8948e-02,  9.4890e-02,\n",
      "         -2.8255e-02,  2.9813e-02, -8.4482e-02,  1.5628e-02, -3.8181e-02, -5.1697e-02,  3.8091e-02, -2.5244e-02, -8.5568e-02,  8.3622e-02,  7.4758e-02,  6.9699e-02],\n",
      "        [-7.9916e-02, -4.6259e-02,  5.9709e-02,  5.5058e-02,  2.2991e-02,  2.2318e-02,  1.0059e-02,  1.1440e-02, -7.9863e-02,  6.8554e-02,  5.3478e-02, -5.9870e-02,  2.9305e-02,  5.9975e-02, -1.6664e-02, -2.7654e-02, -5.5292e-02, -5.2705e-02,  1.7376e-02,  3.3703e-02, -2.8344e-02,  1.3623e-02,\n",
      "         -6.1272e-02,  1.7236e-02, -2.5379e-02, -6.1715e-02, -2.6844e-03, -9.0166e-02, -8.1013e-02, -3.6099e-02,  1.6340e-02, -9.4729e-03,  6.4595e-02, -1.5547e-02,  8.3262e-02,  8.5267e-02, -4.1285e-02,  5.1265e-02, -3.3741e-02, -3.8084e-02,  3.4698e-02,  1.0667e-02,  6.8611e-02,  8.3447e-04,\n",
      "          5.2190e-02,  6.3809e-03,  8.0560e-02,  3.8266e-02, -4.0784e-02,  1.6232e-02,  5.8650e-02, -8.8082e-02, -9.0244e-02,  1.1361e-02, -7.6133e-02, -4.6376e-02, -1.3536e-03,  8.8909e-02, -5.5091e-02,  3.9260e-02, -8.9820e-02,  7.0665e-02, -7.6580e-02, -4.9347e-02,  3.0208e-02, -1.0161e-02,\n",
      "          6.8252e-02,  2.3033e-02,  6.2900e-02,  4.8745e-02,  7.2274e-02,  9.6165e-02,  7.8269e-05, -7.0609e-02,  9.3458e-02,  3.4084e-02,  6.0877e-02, -4.1466e-02, -3.6897e-03,  3.2344e-03,  6.6475e-03, -1.8404e-02,  5.9925e-02,  7.9803e-02, -1.0214e-02, -2.2673e-02,  5.3277e-02,  7.9631e-02,\n",
      "         -1.5263e-02,  6.0234e-02, -6.8944e-02, -5.4547e-02,  8.8221e-02,  2.5488e-02,  8.5602e-03, -7.1271e-02, -1.2722e-02, -7.2317e-02,  5.1623e-02,  6.2232e-02],\n",
      "        [ 2.9157e-03,  5.6055e-02,  9.6794e-02,  8.8709e-02, -4.6573e-02, -9.1998e-02,  6.1429e-02, -2.5780e-02,  6.3914e-02, -6.1590e-03, -3.1789e-03, -1.2537e-02,  4.0210e-02, -6.8660e-02,  9.5957e-02, -8.2417e-02,  9.5976e-02, -7.5864e-02,  4.0975e-02,  4.3686e-02, -3.5945e-02, -7.2976e-02,\n",
      "          4.1555e-02, -5.7239e-02,  9.7566e-02, -2.9023e-02, -2.8334e-02,  8.7518e-03,  2.9194e-02, -3.3832e-02,  8.3112e-03, -4.3468e-02,  9.6756e-02, -1.6707e-02,  4.0426e-02, -2.6456e-02, -1.9619e-02, -4.9521e-03, -1.3006e-03,  9.1375e-02, -2.7417e-03,  2.1330e-02, -5.8453e-02,  4.9311e-02,\n",
      "         -5.4771e-02, -3.7149e-03, -7.6079e-02, -8.1318e-02,  7.3137e-02,  7.1941e-02, -6.3941e-02, -8.4085e-02, -4.5678e-02, -6.0235e-02,  1.1898e-02,  5.6508e-03, -3.1006e-02, -7.9010e-02,  6.8291e-02, -8.1265e-02,  3.9412e-02,  4.7998e-02, -2.5191e-02, -3.7772e-02, -5.1825e-02, -4.4556e-02,\n",
      "         -1.9490e-02, -3.3089e-02,  7.2206e-02,  5.6407e-03, -5.0944e-03, -7.4075e-02,  9.8064e-03, -1.3785e-02, -9.7424e-02, -1.8039e-02, -2.7742e-02, -5.8623e-02,  1.9904e-02, -9.0868e-02,  3.7735e-02, -8.1524e-02,  2.5936e-02,  5.6523e-02,  1.4072e-02, -6.3261e-02,  3.9255e-02, -2.4760e-02,\n",
      "         -6.5023e-02,  1.8723e-02,  1.6895e-02, -8.4900e-02, -3.2197e-02,  4.4244e-02, -6.9660e-02,  1.8886e-02,  6.7671e-02,  5.1658e-02,  1.2269e-02, -7.5298e-03],\n",
      "        [-5.7958e-02,  4.1223e-02,  3.3258e-02,  2.4176e-02, -8.3467e-02,  5.2552e-02, -8.8468e-02,  3.9051e-02,  2.6473e-02, -5.9958e-02, -5.9589e-02, -2.3843e-02,  3.4276e-04, -4.0373e-02, -4.0309e-02,  2.1904e-02, -8.6213e-02,  8.6798e-02,  9.6572e-02,  2.3592e-02, -6.5535e-02, -9.8597e-03,\n",
      "         -6.6684e-02, -2.1954e-02,  5.0778e-02,  5.2211e-02,  1.3665e-02, -6.4869e-02,  7.1237e-02, -9.1893e-02, -4.3828e-02,  4.7075e-02,  5.1846e-02, -5.0716e-02,  6.3073e-02,  9.5760e-02, -6.7148e-02,  5.1317e-02, -2.9750e-02, -8.4698e-02,  4.0958e-02, -3.1558e-02, -4.6482e-02,  5.7485e-03,\n",
      "         -1.2638e-02,  2.9441e-02,  2.0428e-02,  5.8984e-02, -4.9043e-02,  4.4069e-03, -8.7641e-02, -2.8408e-02, -9.8357e-02, -1.8995e-02,  3.7520e-02, -5.0367e-02,  7.5657e-03, -1.8216e-02, -2.8238e-02, -4.0156e-02, -1.4857e-02,  6.4317e-02, -7.7543e-02,  6.1499e-03, -4.8616e-02, -4.7900e-02,\n",
      "         -6.4203e-02,  1.7517e-03, -8.6192e-02, -2.3361e-02,  1.6597e-02,  9.5858e-04,  1.4544e-03, -6.6451e-02, -5.5225e-02, -7.6215e-02, -6.2670e-02,  4.0125e-02, -5.5549e-02,  7.0316e-02, -8.6830e-02, -8.8830e-02,  9.3810e-02, -8.8104e-02, -4.5038e-02,  7.4599e-02,  4.2483e-02, -4.8183e-02,\n",
      "          9.4398e-02,  5.1596e-02,  3.5604e-02,  6.6509e-02, -1.4827e-02,  3.7576e-02, -1.3673e-02,  1.0364e-02,  3.7518e-02, -3.3276e-02, -6.0702e-02, -7.8505e-02],\n",
      "        [-7.0806e-02,  1.9528e-02,  7.9112e-02,  9.2194e-02,  2.2606e-02, -6.1248e-02, -7.6824e-02, -9.9314e-02,  4.2628e-03,  8.4848e-02, -9.1161e-02,  4.7416e-02,  9.4516e-02,  9.2321e-02, -6.5316e-02,  2.5383e-03,  4.0660e-02,  3.6348e-02,  9.6962e-03, -5.3137e-02,  9.9131e-02, -1.0011e-02,\n",
      "         -2.9367e-02, -6.7517e-02,  5.6093e-02,  1.2592e-02, -6.0802e-02,  2.3738e-02, -1.2006e-02,  1.9146e-02,  1.9826e-02, -3.9721e-02,  1.5467e-02, -2.0978e-02, -3.7055e-02, -8.5840e-02, -4.2528e-02,  2.8142e-02,  5.8122e-02,  9.2850e-02, -4.9655e-02, -5.1144e-02, -7.8042e-02, -2.0670e-03,\n",
      "         -9.6393e-02, -2.6747e-02,  9.6948e-02, -3.9675e-02, -4.4481e-03, -5.5131e-02,  7.6082e-02,  2.9504e-04, -8.1175e-02, -9.6278e-02, -4.0882e-02,  1.0443e-02, -7.3982e-03, -2.3223e-03, -9.5432e-02, -4.9596e-02,  3.5534e-03, -8.9883e-02,  6.1658e-02,  7.2381e-02, -7.2006e-02,  6.0297e-02,\n",
      "          8.7148e-02, -6.1348e-02, -3.3596e-02, -5.2586e-02, -8.8746e-02,  4.4521e-02,  3.3675e-02,  9.2828e-02,  8.4219e-02,  9.5528e-02, -4.7088e-02, -9.4617e-02, -5.2068e-02, -3.5680e-02,  1.3824e-02,  8.1546e-03, -3.6643e-02,  1.6128e-02, -5.2901e-02, -4.8015e-02,  9.0286e-02,  8.1614e-02,\n",
      "         -6.1675e-02, -3.3909e-02,  8.4584e-02,  1.2338e-02, -7.2733e-02,  3.2539e-02,  5.2265e-02,  5.5847e-02, -3.8760e-02, -7.8528e-02, -3.1608e-02,  2.6734e-02],\n",
      "        [-2.7049e-03,  4.0648e-02,  2.4674e-03,  6.8195e-02, -8.8738e-02,  5.6129e-02, -1.5411e-02,  9.1881e-03,  9.7794e-02, -9.4262e-03,  6.1682e-03, -9.8068e-02, -2.5245e-02,  5.7455e-02,  5.9371e-02,  9.6437e-02,  5.6362e-02, -2.3968e-02, -1.7488e-02, -1.0225e-01, -2.0857e-02,  6.7612e-02,\n",
      "          8.4923e-02,  2.8899e-02, -1.4809e-02,  8.7590e-02, -5.3130e-02, -3.4333e-02,  5.6529e-02,  2.7098e-02,  7.3205e-02, -9.2251e-02,  9.7097e-02, -1.0446e-01,  1.6861e-02,  2.0144e-02,  7.7008e-02,  1.1590e-02,  4.8089e-02, -7.3353e-02,  2.3495e-02, -9.7783e-02,  7.3386e-02,  4.1560e-02,\n",
      "          3.8082e-03,  4.0820e-02, -3.1602e-02,  2.1909e-02, -3.3278e-02, -5.6469e-02, -5.7730e-02, -5.9628e-02,  3.5612e-02, -1.6597e-02, -1.3235e-02,  3.8480e-02,  9.1647e-02, -9.0983e-02,  5.1511e-03, -5.2126e-03, -3.2267e-02,  6.2603e-02,  1.2769e-02, -5.1266e-02, -1.1596e-02,  1.8878e-02,\n",
      "         -9.5196e-02,  2.0703e-02, -2.3528e-02,  8.2110e-03, -7.3043e-02, -3.5532e-02,  9.3778e-02,  7.8817e-02,  4.2138e-02,  8.2070e-02,  8.0160e-02, -5.8009e-02, -7.9464e-02,  1.6002e-02,  4.7954e-02,  5.0394e-02,  5.0237e-02, -7.0317e-02, -7.9604e-02,  9.6801e-02, -2.8167e-02,  3.6113e-02,\n",
      "         -9.2220e-02,  8.9567e-02,  2.2855e-02, -2.6284e-02,  5.3701e-02, -1.1453e-02, -1.0354e-02, -3.0723e-02,  4.9730e-02,  3.5279e-02, -8.1051e-02, -1.4690e-02],\n",
      "        [-3.4583e-02,  1.1256e-02,  1.9576e-02, -6.6168e-02, -2.3802e-02,  3.1979e-02, -3.0809e-02,  2.0356e-02, -8.7797e-02, -5.8978e-02,  6.3065e-02, -3.8816e-02,  6.2343e-02, -6.7134e-02,  8.6277e-03,  7.2274e-02, -4.6661e-02,  7.4294e-02,  4.8852e-02,  8.3362e-02, -9.7913e-02,  8.7636e-03,\n",
      "         -2.0835e-02,  1.6769e-02,  3.2772e-02,  6.0054e-02, -6.3349e-02,  6.8142e-02,  6.4682e-02,  7.9257e-02,  4.3060e-02, -8.9962e-02,  9.7855e-03,  1.2936e-02,  8.0460e-02, -6.1465e-02, -1.3236e-02, -8.8466e-02,  8.1589e-02,  1.0621e-02, -6.6912e-02,  8.5506e-02,  7.5354e-02,  6.0412e-02,\n",
      "         -7.8735e-02,  6.0373e-02, -3.2830e-02,  7.3749e-02, -1.6702e-02, -1.6599e-02, -5.3302e-02, -7.0469e-03, -2.4857e-02, -1.9594e-02,  7.1090e-02, -6.2775e-02, -7.4433e-02, -6.4044e-02,  4.6828e-02, -8.6164e-02, -3.1575e-02, -4.3656e-02, -1.6719e-02, -2.1659e-02, -6.8448e-02,  8.2961e-02,\n",
      "          2.5517e-02, -2.5224e-03, -7.3195e-02, -5.3417e-02,  5.1799e-02,  8.9236e-02,  6.6561e-02,  6.7163e-02, -9.0238e-02,  8.1130e-02, -8.0834e-02,  7.9779e-02, -1.7539e-02, -2.4548e-02, -2.9035e-02,  7.7136e-02,  6.8428e-02, -3.1012e-02, -7.7799e-02,  3.3791e-02, -6.5279e-02, -7.8427e-02,\n",
      "         -8.4862e-02, -6.1919e-02,  8.1921e-02, -5.8071e-03, -2.3921e-02,  7.3868e-02,  7.4242e-02,  2.2550e-02, -6.4205e-02,  1.6643e-02, -8.9121e-02, -8.3160e-02],\n",
      "        [ 8.9528e-02, -9.1389e-02,  2.1749e-02,  2.9251e-02, -3.5793e-02,  3.7394e-02, -4.2589e-02, -1.5377e-02,  8.7851e-02, -2.3422e-03,  3.1905e-02, -6.9283e-02,  9.9098e-02, -2.0144e-03,  3.2527e-02,  5.5307e-04, -3.5258e-02, -3.0613e-02, -9.7984e-02,  2.4462e-03, -1.7607e-02, -6.7992e-02,\n",
      "          4.2443e-02,  2.1657e-02,  9.0391e-02, -7.8553e-02,  2.3069e-02,  7.0150e-02,  6.8550e-02, -4.4383e-02,  4.6650e-02,  9.4722e-02,  7.8054e-02,  3.5866e-02, -7.4813e-02,  3.7717e-03,  4.5975e-02, -6.5378e-02, -2.7640e-02, -1.0257e-01, -6.9314e-02,  7.3138e-03, -1.3564e-02,  5.8091e-02,\n",
      "          1.0621e-02, -6.6638e-02,  2.4521e-02, -7.7230e-02,  1.8576e-02,  6.1202e-02,  5.1003e-02,  5.7684e-02, -3.9525e-02, -3.0707e-02,  6.7633e-02,  1.5242e-03,  4.2874e-05,  7.8010e-02,  5.3540e-02,  4.3432e-02,  6.2001e-02,  2.3205e-02, -9.4486e-02,  4.4010e-02, -6.8593e-03,  3.4930e-03,\n",
      "         -3.9809e-02,  6.4229e-02, -7.6459e-02,  4.7818e-02, -9.6292e-02,  3.3370e-02, -7.0695e-02, -3.5479e-02,  7.8103e-02,  1.0065e-01,  2.0055e-02,  4.9472e-02, -1.0010e-02,  7.7368e-02, -6.5163e-02, -1.8421e-02,  2.2431e-02,  8.2636e-02, -1.4995e-03, -1.7607e-02, -7.5099e-02,  7.4428e-02,\n",
      "         -5.5459e-02, -1.0230e-02, -3.4877e-02, -1.1054e-02,  3.9911e-02,  3.2602e-02, -7.3853e-02, -1.9820e-02,  7.6663e-02,  1.8607e-02,  5.4375e-02,  5.9019e-02]], device='cuda:0')\n",
      "fc2.bias \t tensor([-0.0235, -0.0609, -0.0477, -0.0584,  0.0672,  0.0955, -0.0978,  0.0314, -0.0742, -0.0432], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in cnn_model.state_dict():\n",
    "    print(i, \"\\t\", cnn_model.state_dict()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183524a-0c74-49ac-8a56-33405f99f927",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 10: Use trained CNN model to predict (for comparison to Step 11)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b4152-139d-422a-b03f-d50475da4781",
   "metadata": {},
   "source": [
    "**Use trained model for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf0b48ab-9cf1-4ac3-83f2-a2a2eccdcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual labels for comparison\n",
    "\n",
    "dataiter = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3ba7f34-b0bc-452e-9fda-200a8e6ad71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- outputs ----------\n",
      "tensor([[-1.2500, -0.3900,  1.1400,  1.7300,  0.4700,  1.6300,  1.3400, -2.6300, -0.3000, -2.0300],\n",
      "        [ 4.1600,  5.9700, -0.9300, -0.5600, -3.0200, -3.4200, -4.0400, -2.7100,  5.3300,  5.9300],\n",
      "        [ 2.4100,  2.2900, -0.9900,  1.1800, -1.1600, -1.4100, -4.5600, -2.0700,  2.4200,  3.8700],\n",
      "        [ 2.4500,  2.1300,  0.6400, -0.2900, -0.5600, -1.2500, -0.5600,  0.4900,  3.5800,  1.0900],\n",
      "        [ 0.0600, -0.8100,  3.0300,  2.0900,  4.5700,  2.2400,  3.8300,  2.0300, -0.2900, -1.3200],\n",
      "        [-1.1500,  0.8900,  0.8500,  2.3200,  0.8300,  1.6300,  2.6300,  0.1700, -2.3200,  1.1800],\n",
      "        [-0.7100,  5.0800,  0.7000,  4.0500, -1.8800,  0.2700, -0.3100, -0.7400, -1.0700,  3.7900],\n",
      "        [ 0.4400, -0.4700,  2.6900,  2.4100,  2.1000,  0.7600,  4.0800,  1.0000, -1.6600, -1.5000],\n",
      "        [ 1.1100, -1.2700,  2.7700,  2.9500,  2.5600,  3.3700,  0.7000,  1.6800, -1.7400, -2.2600],\n",
      "        [ 3.7000,  7.3900,  0.3100,  0.8400, -2.6000, -2.1200, -2.3100, -1.8600,  3.4100,  4.3900],\n",
      "        [ 2.6100, -0.8000,  0.4100,  1.2900, -0.1900,  2.3000, -2.9100, -0.6200,  3.4900, -1.3300],\n",
      "        [-0.2500,  4.5600, -0.8500, -0.7300, -2.1400, -1.3300, -2.0900,  0.3800,  0.7800,  7.1500],\n",
      "        [ 0.3800,  1.5700,  1.2300,  2.3900,  1.4500,  2.4000,  0.7800,  0.5400, -1.9100, -0.5600],\n",
      "        [ 0.5600,  3.3400,  0.6300, -0.0200, -1.2800, -0.8500,  2.1500,  0.6300, -0.9200,  1.4600],\n",
      "        [ 1.2200,  6.7300,  0.6100, -0.7600, -1.6800, -1.8700, -2.0700,  0.5700,  1.8100,  6.5100],\n",
      "        [ 0.6300, -0.6500,  1.3900,  0.1700,  1.8400,  1.7800,  1.7100, -0.0300,  2.0500, -0.9100],\n",
      "        [ 0.4000,  0.6700,  0.7100,  2.3100,  0.1200,  3.7700, -0.9600,  2.2100,  1.3500, -1.3700],\n",
      "        [-0.2100, -1.3300,  0.1900,  0.8700,  1.8400,  1.6600,  1.3700,  2.0100, -0.4300,  0.8700],\n",
      "        [ 1.3100,  2.3100, -2.7300,  0.0200, -3.8100, -1.9400, -2.2800, -2.1400,  6.3400,  3.6900],\n",
      "        [-1.4000, -0.1900,  2.5700,  2.4700,  2.9900,  0.8600,  5.9900,  2.1400, -2.2100,  0.0000],\n",
      "        [ 1.7200,  0.6800,  1.5000, -0.2000,  2.5200,  1.0300,  0.0200,  5.2400, -1.5900,  0.9700],\n",
      "        [ 6.9100,  0.0100,  4.0700,  1.4800,  2.2800,  1.0300, -1.2600,  2.0100,  1.4000, -0.9100],\n",
      "        [ 2.1900, -0.6200,  2.3900,  0.8400,  0.8500, -0.7800, -2.1700, -1.3700,  1.1100, -1.1100],\n",
      "        [-0.5300,  7.9100, -5.2300, -2.9000, -2.3700,  1.1400,  0.7200,  2.1700,  1.0900,  6.3500]], device='cuda:0')\n",
      "---------- highest energy ----------\n",
      "torch.return_types.max(\n",
      "values=tensor([1.7327, 5.9681, 3.8721, 3.5766, 4.5680, 2.6252, 5.0832, 4.0782, 3.3709, 7.3892, 3.4930, 7.1477, 2.4039, 3.3377, 6.7292, 2.0531, 3.7675, 2.0116, 6.3448, 5.9934, 5.2396, 6.9136, 2.3949, 7.9118], device='cuda:0'),\n",
      "indices=tensor([3, 1, 9, 8, 4, 6, 1, 6, 5, 1, 8, 9, 5, 1, 1, 8, 5, 7, 8, 6, 7, 0, 2, 1], device='cuda:0'))\n",
      "---------- predicted ----------\n",
      "tensor([3, 1, 9, 8, 4, 6, 1, 6, 5, 1, 8, 9, 5, 1, 1, 8, 5, 7, 8, 6, 7, 0, 2, 1], device='cuda:0')\n",
      "---------- actual ----------\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9], device='cuda:0')\n",
      "---------- total ----------\n",
      "24\n",
      "---------- correct ----------\n",
      "14\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------- outputs ----------\n",
      "tensor([[ 1.5000, -2.2200,  3.6700,  1.9100,  4.3000,  3.1400,  1.7700,  3.1000, -1.6300, -2.3400],\n",
      "        [-0.9900, -1.4400,  3.2300, -0.5800,  2.3900,  0.4400,  2.8100, -0.2300, -1.0900, -1.6600],\n",
      "        [ 0.3600, -0.2200,  1.0900,  2.2500,  2.0500,  1.5000,  1.5600,  1.3700, -1.3500, -0.3200],\n",
      "        [ 1.8100, -0.7000,  1.2500,  0.7100,  1.0600,  0.3600,  0.0800,  1.7800, -0.2100,  1.0400],\n",
      "        [ 0.9800,  6.6900, -0.1800,  0.7500, -0.3900,  1.1300, -0.7100,  1.8400, -1.4800,  5.0200],\n",
      "        [ 0.4800,  0.8000,  1.4900,  0.8700,  1.2400,  2.5800,  1.3900,  2.3200, -3.9800,  0.1100],\n",
      "        [-1.1600,  1.8400, -0.1600,  0.8200, -0.8500,  1.3600,  1.6000,  1.3000, -3.0300,  0.6500],\n",
      "        [ 1.6500, -1.8300,  2.9200,  2.9400,  2.6700,  4.2400,  0.2300,  1.8500, -0.8200, -2.2700],\n",
      "        [ 1.0400, -0.3500,  2.0000,  1.3200,  1.8200,  0.9900,  1.9300,  1.6200, -0.0400, -0.8000],\n",
      "        [ 0.0200, -0.1800,  1.8400,  2.5200,  0.9000,  2.1600,  2.2500,  1.3700, -1.8000, -1.9300],\n",
      "        [ 1.5700,  0.7800, -0.4500, -0.6000, -0.1500, -1.1800, -2.7000,  2.0000,  1.6100,  3.3900],\n",
      "        [ 1.0000,  4.6200, -0.8200, -0.9900, -1.7200, -1.7400, -0.6200,  0.5800,  0.4200,  3.9900],\n",
      "        [ 1.3400,  1.0100,  1.0300,  2.1300,  1.8600,  1.6900,  2.1900,  2.2200, -2.2300, -0.0300],\n",
      "        [ 2.2000,  5.6100, -2.7100, -0.4000, -1.4800, -1.3700,  0.2100, -0.5500,  4.0600,  5.1700],\n",
      "        [ 2.0600,  6.3400, -1.3300, -0.4900, -0.9100, -0.8900,  1.4700,  0.3100,  0.9600,  4.5400],\n",
      "        [ 0.6100, -1.4000,  2.0500,  2.6600,  1.0800,  3.4400,  0.5300, -0.2600,  1.3600, -2.7400],\n",
      "        [ 3.5800,  2.4000,  1.3700,  0.2300,  2.5900, -0.1900, -0.8500,  3.6700,  2.3200,  2.8500],\n",
      "        [-0.9700, -1.6500,  2.0100,  1.6800,  0.9600,  0.7700,  3.7700,  0.9000, -0.7000, -0.8900],\n",
      "        [ 0.7000,  2.1900, -0.7800,  1.4300, -0.9600,  0.3200, -0.3400,  0.9700, -0.7300,  3.1400],\n",
      "        [-0.2100,  0.3500,  0.9300,  2.1400,  1.7600,  1.6500,  2.5400,  0.4800, -1.5300,  0.1200],\n",
      "        [ 2.4500,  2.9500,  0.6500, -3.1300,  0.1600, -5.0500, -8.6300,  0.9200,  2.3600,  5.3000],\n",
      "        [ 4.1900,  3.7800,  0.1400, -0.8600, -0.2400, -1.1200, -2.7800,  1.7700,  5.0600,  5.7800],\n",
      "        [-0.6800,  0.1700,  2.7400,  5.0100,  1.4900,  3.9500,  1.9200, -0.0100, -0.2600, -0.6900],\n",
      "        [-0.4800,  0.5300, -0.6300,  1.1300, -1.0100,  1.8500, -1.3600,  2.7200, -0.3900,  1.0900]], device='cuda:0')\n",
      "---------- highest energy ----------\n",
      "torch.return_types.max(\n",
      "values=tensor([4.2967, 3.2301, 2.2510, 1.8136, 6.6924, 2.5769, 1.8368, 4.2389, 1.9990, 2.5180, 3.3862, 4.6248, 2.2240, 5.6081, 6.3409, 3.4410, 3.6651, 3.7682, 3.1423, 2.5405, 5.3023, 5.7848, 5.0111, 2.7210], device='cuda:0'),\n",
      "indices=tensor([4, 2, 3, 0, 1, 5, 1, 5, 2, 3, 9, 1, 7, 1, 1, 5, 7, 6, 9, 6, 9, 9, 3, 7], device='cuda:0'))\n",
      "---------- predicted ----------\n",
      "tensor([4, 2, 3, 0, 1, 5, 1, 5, 2, 3, 9, 1, 7, 1, 1, 5, 7, 6, 9, 6, 9, 9, 3, 7], device='cuda:0')\n",
      "---------- actual ----------\n",
      "tensor([5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9], device='cuda:0')\n",
      "---------- total ----------\n",
      "48\n",
      "---------- correct ----------\n",
      "24\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)   # class with highest energy choosen as prediction\n",
    "        print('---------- outputs ----------')\n",
    "        print(torch.round(outputs.data, decimals=2))\n",
    "        print('---------- highest energy ----------')\n",
    "        print(torch.max(outputs.data, 1))\n",
    "        print('---------- predicted ----------')\n",
    "        print(predicted.data)\n",
    "        images, labels = next(dataiter)\n",
    "        print('---------- actual ----------')\n",
    "        print(labels.data)\n",
    "        total = total + labels.size(0)\n",
    "        print('---------- total ----------')\n",
    "        print(total)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        print('---------- correct ----------')\n",
    "        print(correct)\n",
    "        print()\n",
    "        print('--------------------------------------------------------------------------------')\n",
    "        print()\n",
    "        i = i + 1\n",
    "        if i == 3:   # test on first 2 batches\n",
    "            break\n",
    "\n",
    "print()\n",
    "print(f'Accuracy: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea8e41-91d6-48a1-8f21-9d2c865741f3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **Step 11: Use saved trained CNN model to predict (for comparison to Step 10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e06a6e-0577-4528-91be-d28940e9e1a5",
   "metadata": {},
   "source": [
    "**Load saved trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5fd99d7-33fc-4a30-bb93-878e6878e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trained_cnn_model = torch.load('trained_cnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf39b3-1098-41e8-b3d7-ad2f026fbbea",
   "metadata": {},
   "source": [
    "**Check saved trained model is correct at high level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea6970ed-bb94-4c0b-a876-7369a72965f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([9, 3, 3, 3])\n",
      "conv1.bias \t torch.Size([9])\n",
      "fc1.weight \t torch.Size([100, 2304])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([10, 100])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in my_trained_cnn_model.state_dict():\n",
    "    print(i, \"\\t\", my_trained_cnn_model.state_dict()[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862c801-48c2-49b9-afba-a63ee78d5d45",
   "metadata": {},
   "source": [
    "**Check saved trained model is correct at low level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15c09be1-897b-41df-a072-f4fb4e45b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t tensor([[[[ 0.1181,  0.1192, -0.0612],\n",
      "          [ 0.1412, -0.0890, -0.0057],\n",
      "          [-0.0852,  0.0963,  0.1388]],\n",
      "\n",
      "         [[-0.1616,  0.1376,  0.0259],\n",
      "          [ 0.1096, -0.0147,  0.0501],\n",
      "          [-0.0273,  0.1266, -0.0075]],\n",
      "\n",
      "         [[-0.0902,  0.0423, -0.0808],\n",
      "          [-0.0276, -0.0875,  0.1123],\n",
      "          [-0.1353, -0.0887, -0.0702]]],\n",
      "\n",
      "\n",
      "        [[[-0.1148,  0.0483, -0.1807],\n",
      "          [ 0.1795, -0.1656,  0.1354],\n",
      "          [ 0.0133, -0.0787,  0.0932]],\n",
      "\n",
      "         [[ 0.0189,  0.1672,  0.0135],\n",
      "          [-0.0602,  0.0392, -0.0724],\n",
      "          [ 0.0563,  0.1437,  0.0759]],\n",
      "\n",
      "         [[-0.0980,  0.1196,  0.0250],\n",
      "          [ 0.0991, -0.1257, -0.2068],\n",
      "          [-0.0929, -0.1680,  0.1281]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0466,  0.0819,  0.0629],\n",
      "          [-0.0106,  0.1462, -0.1405],\n",
      "          [ 0.0107, -0.1419,  0.0471]],\n",
      "\n",
      "         [[-0.0683,  0.0642, -0.0404],\n",
      "          [ 0.1599, -0.1129, -0.1178],\n",
      "          [-0.1096,  0.1680,  0.0545]],\n",
      "\n",
      "         [[ 0.1839, -0.1529, -0.1875],\n",
      "          [-0.1477, -0.1254,  0.0807],\n",
      "          [ 0.0760,  0.1575, -0.1032]]],\n",
      "\n",
      "\n",
      "        [[[-0.1326,  0.1001, -0.0805],\n",
      "          [ 0.1147, -0.0477,  0.1077],\n",
      "          [-0.1497, -0.0974,  0.0584]],\n",
      "\n",
      "         [[ 0.0393, -0.0507,  0.1123],\n",
      "          [ 0.1289, -0.1412, -0.1047],\n",
      "          [ 0.1761, -0.0651, -0.0684]],\n",
      "\n",
      "         [[-0.1864, -0.1106,  0.0470],\n",
      "          [-0.0259, -0.1401,  0.0037],\n",
      "          [-0.1315, -0.1633, -0.1061]]],\n",
      "\n",
      "\n",
      "        [[[-0.1685, -0.1229,  0.1911],\n",
      "          [ 0.0362,  0.0595, -0.1796],\n",
      "          [-0.1264, -0.0637,  0.0302]],\n",
      "\n",
      "         [[-0.1695, -0.0830, -0.1162],\n",
      "          [ 0.0003, -0.0709, -0.0129],\n",
      "          [-0.1305, -0.1315, -0.1119]],\n",
      "\n",
      "         [[-0.0659, -0.1525,  0.1597],\n",
      "          [-0.0383,  0.1661,  0.0602],\n",
      "          [-0.1629,  0.1337, -0.0526]]],\n",
      "\n",
      "\n",
      "        [[[-0.0644, -0.1571, -0.1687],\n",
      "          [ 0.0357, -0.0765,  0.0847],\n",
      "          [-0.1559,  0.1165, -0.1290]],\n",
      "\n",
      "         [[-0.0235,  0.0436,  0.1200],\n",
      "          [ 0.1408,  0.1467, -0.1401],\n",
      "          [ 0.0535, -0.1043, -0.0066]],\n",
      "\n",
      "         [[-0.1290,  0.1847, -0.1179],\n",
      "          [ 0.0981,  0.0482,  0.0820],\n",
      "          [-0.0918,  0.1615,  0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0416, -0.1551,  0.0942],\n",
      "          [-0.0243, -0.0832,  0.1736],\n",
      "          [ 0.0378, -0.1031, -0.0916]],\n",
      "\n",
      "         [[-0.0024,  0.1120, -0.0490],\n",
      "          [-0.1149, -0.0702, -0.1465],\n",
      "          [ 0.0568,  0.1459, -0.1816]],\n",
      "\n",
      "         [[ 0.0485,  0.1011,  0.0289],\n",
      "          [-0.0766,  0.0939,  0.0932],\n",
      "          [ 0.0507, -0.0465, -0.0636]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0269, -0.0357, -0.0327],\n",
      "          [ 0.1180,  0.1560,  0.0006],\n",
      "          [-0.0495, -0.0111, -0.0032]],\n",
      "\n",
      "         [[ 0.0483,  0.0460, -0.1601],\n",
      "          [-0.0772,  0.1510,  0.0894],\n",
      "          [-0.0154, -0.1314, -0.1128]],\n",
      "\n",
      "         [[-0.1542, -0.0615,  0.0867],\n",
      "          [ 0.1324,  0.0844, -0.1509],\n",
      "          [-0.1058, -0.0388,  0.1920]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0324, -0.0443,  0.0806],\n",
      "          [-0.0698, -0.1192,  0.1409],\n",
      "          [-0.0847, -0.0304, -0.1831]],\n",
      "\n",
      "         [[ 0.1292,  0.1471,  0.0669],\n",
      "          [-0.1336, -0.1874, -0.1587],\n",
      "          [ 0.1447,  0.0987,  0.1686]],\n",
      "\n",
      "         [[ 0.1018,  0.0506, -0.0039],\n",
      "          [-0.1439, -0.1602, -0.1797],\n",
      "          [ 0.0811, -0.0870, -0.0303]]]], device='cuda:0')\n",
      "conv1.bias \t tensor([-0.1095, -0.0339, -0.1356, -0.1257,  0.0638, -0.0573,  0.1191, -0.0626, -0.1412], device='cuda:0')\n",
      "fc1.weight \t tensor([[-0.0041, -0.0106, -0.0069,  ..., -0.0077,  0.0036, -0.0145],\n",
      "        [ 0.0007,  0.0090,  0.0118,  ..., -0.0092, -0.0051,  0.0072],\n",
      "        [-0.0033,  0.0068,  0.0036,  ...,  0.0154,  0.0029, -0.0016],\n",
      "        ...,\n",
      "        [-0.0041, -0.0076, -0.0009,  ..., -0.0064, -0.0139,  0.0184],\n",
      "        [-0.0147,  0.0104,  0.0048,  ..., -0.0057, -0.0204, -0.0166],\n",
      "        [ 0.0180,  0.0159, -0.0096,  ...,  0.0117, -0.0114, -0.0046]], device='cuda:0')\n",
      "fc1.bias \t tensor([-0.0051,  0.0119,  0.0098,  0.0161,  0.0202,  0.0080,  0.0032, -0.0131, -0.0117,  0.0045,  0.0026,  0.0004,  0.0031,  0.0055,  0.0142,  0.0031, -0.0056,  0.0033,  0.0201,  0.0128,  0.0026,  0.0123,  0.0052,  0.0080, -0.0077,  0.0127, -0.0121, -0.0152, -0.0154, -0.0165, -0.0116,  0.0057,\n",
      "         0.0192, -0.0003, -0.0057,  0.0066,  0.0200,  0.0029,  0.0125, -0.0110, -0.0005, -0.0030,  0.0041,  0.0190,  0.0141, -0.0008,  0.0068, -0.0184,  0.0002, -0.0031,  0.0144,  0.0046, -0.0057, -0.0125, -0.0104,  0.0045,  0.0149,  0.0179, -0.0163,  0.0011,  0.0146,  0.0159,  0.0122, -0.0159,\n",
      "         0.0118,  0.0168, -0.0161, -0.0008,  0.0096, -0.0181, -0.0168,  0.0175,  0.0206, -0.0149,  0.0039, -0.0142, -0.0164, -0.0155,  0.0028, -0.0027,  0.0026, -0.0050,  0.0168, -0.0028,  0.0127, -0.0165, -0.0171,  0.0171, -0.0046,  0.0019, -0.0050, -0.0105, -0.0093,  0.0032,  0.0132, -0.0060,\n",
      "         0.0143,  0.0176,  0.0108, -0.0119], device='cuda:0')\n",
      "fc2.weight \t tensor([[ 3.5779e-02,  5.9280e-02,  1.1996e-04,  1.7265e-02, -8.1061e-02, -9.4740e-02, -7.9394e-02, -1.5369e-02, -2.4553e-02,  6.0809e-03,  6.6896e-02, -1.1984e-02, -4.7694e-02, -5.9700e-02, -7.6712e-02, -7.3467e-02,  2.5620e-02,  5.9196e-02, -7.8656e-03,  5.6720e-02,  7.8295e-02, -1.8023e-02,\n",
      "         -9.6957e-02,  7.0610e-02, -2.3190e-02, -3.0406e-02,  6.6599e-02, -2.9039e-02, -4.9890e-02, -2.8228e-02, -8.3863e-02, -4.2364e-02, -7.5913e-02,  3.7087e-02, -8.4170e-02, -1.6101e-02,  5.6960e-02, -5.7450e-02, -5.5289e-02, -7.8649e-02,  3.0220e-02,  6.8565e-02,  5.0409e-03, -7.5921e-02,\n",
      "          4.9805e-03, -2.9019e-02, -5.5263e-02, -6.5321e-02,  3.8554e-02,  5.1663e-02,  2.8580e-02, -4.8667e-02,  2.1511e-02,  5.2556e-02, -2.9059e-02,  6.4164e-04,  7.8593e-02,  8.8472e-02,  5.7926e-02,  7.2088e-02, -2.9381e-02,  7.9703e-02, -8.3166e-02, -3.9661e-02,  7.3791e-03,  9.0770e-02,\n",
      "         -4.0084e-02,  4.6789e-02, -9.3442e-02, -2.3375e-02,  4.9196e-02, -4.1504e-02,  4.1534e-02,  6.8383e-02, -8.0973e-03, -9.0187e-03,  1.6207e-02, -6.6258e-02, -3.9816e-03, -6.6657e-02,  8.8363e-02,  6.9768e-02, -1.6596e-02, -2.8855e-02, -9.7722e-02,  6.1574e-03, -7.4734e-02,  2.0418e-02,\n",
      "          8.8337e-02,  8.6597e-02,  1.7059e-02,  4.0731e-02, -7.7438e-02,  1.4227e-02, -7.3211e-02, -9.3185e-02, -8.5766e-02,  1.0069e-02,  4.1290e-02,  1.0257e-01],\n",
      "        [ 5.9014e-02, -6.2501e-02, -6.6913e-02,  4.1338e-02, -7.0164e-02,  8.3885e-02, -8.7379e-02,  4.3759e-02,  6.3228e-02, -8.9138e-02,  2.0196e-02,  4.2954e-02,  3.0711e-02,  7.3532e-02,  5.2300e-02, -1.0683e-02, -4.8840e-03, -3.5624e-02,  3.0175e-03, -9.2366e-03,  1.1167e-03, -4.4800e-02,\n",
      "          9.8075e-02, -9.5887e-03, -3.3865e-02, -6.2858e-02, -7.5750e-02,  9.6867e-02,  8.1118e-02, -8.2503e-02, -7.0029e-03, -8.1120e-02, -3.3118e-02,  8.1840e-02,  8.9008e-02,  7.5473e-02,  5.7151e-02,  3.3107e-02,  1.1944e-03,  2.8827e-02,  2.2817e-02,  8.9806e-02,  3.5622e-02, -7.0584e-02,\n",
      "         -9.9608e-03, -2.7105e-02,  1.9299e-02, -5.9259e-02, -4.9642e-02, -2.6446e-02,  5.8916e-02,  4.4819e-02, -6.6513e-02,  4.7425e-04, -3.0804e-02,  2.0976e-02, -8.1720e-02, -5.3530e-02,  4.0898e-02,  6.8111e-02, -6.0111e-03,  4.2906e-02,  6.5850e-02, -2.6804e-03, -1.2530e-02,  6.9658e-02,\n",
      "          5.0477e-02,  9.7111e-02, -9.6204e-02, -3.2177e-02, -2.0089e-03,  5.4973e-02,  7.0434e-02, -6.5039e-02, -2.2999e-02,  9.8244e-02, -8.9666e-02, -3.7996e-02,  3.4870e-02, -8.3295e-03,  6.9529e-02, -6.4993e-02,  4.4575e-02, -8.8523e-03, -4.5565e-02,  6.8869e-02, -6.6131e-02, -1.9682e-02,\n",
      "          9.4415e-02,  6.8675e-02, -9.6754e-02, -1.7897e-02,  3.6081e-02,  9.9008e-03,  6.7267e-02, -5.5221e-03, -2.9967e-02, -4.1571e-02, -5.9243e-02,  2.4768e-02],\n",
      "        [-3.6090e-02,  3.1826e-02,  6.2617e-02, -5.0676e-02, -1.0134e-02, -1.1498e-02,  4.1045e-02, -8.6132e-02, -4.9620e-04,  2.4197e-02, -7.3753e-02,  1.6843e-02,  3.8099e-02, -4.2072e-02,  1.8995e-02,  6.7812e-02,  4.2518e-02, -3.3000e-02,  8.6936e-02, -1.9972e-02,  7.0319e-02,  6.7164e-02,\n",
      "          7.4893e-02, -2.7036e-02,  4.4622e-02, -4.4079e-02,  5.6515e-03, -8.6710e-02, -3.8471e-03, -9.2176e-02, -9.5653e-02,  3.3170e-02, -4.4859e-02, -5.1265e-02,  5.9069e-03,  4.6325e-02,  4.5519e-02,  6.2765e-02,  2.6001e-02,  4.3239e-02,  5.4688e-02, -3.1698e-02, -8.8132e-02,  1.8408e-02,\n",
      "         -6.0245e-02, -2.9017e-02,  4.9443e-02, -5.0673e-02,  8.7065e-02, -6.0653e-02,  9.2462e-02, -8.7838e-02,  2.4208e-02, -2.7319e-02, -2.2739e-02,  1.2330e-03,  3.1136e-03,  9.4994e-02, -4.4782e-02,  1.0384e-02, -8.7042e-02,  7.8410e-02, -2.8221e-02, -9.1177e-02,  9.3757e-02,  5.5299e-02,\n",
      "         -9.3788e-02,  1.3677e-02, -5.6385e-02, -5.1249e-02,  8.7548e-02,  8.4169e-02,  5.8425e-02,  5.9651e-02, -6.7202e-02,  3.5986e-02, -5.8437e-02, -2.7636e-02, -2.1439e-02, -8.1892e-02,  4.4452e-02, -4.8572e-02,  1.3550e-02,  8.3929e-02,  4.7981e-02, -5.8921e-02, -6.8948e-02,  9.4890e-02,\n",
      "         -2.8255e-02,  2.9813e-02, -8.4482e-02,  1.5628e-02, -3.8181e-02, -5.1697e-02,  3.8091e-02, -2.5244e-02, -8.5568e-02,  8.3622e-02,  7.4758e-02,  6.9699e-02],\n",
      "        [-7.9916e-02, -4.6259e-02,  5.9709e-02,  5.5058e-02,  2.2991e-02,  2.2318e-02,  1.0059e-02,  1.1440e-02, -7.9863e-02,  6.8554e-02,  5.3478e-02, -5.9870e-02,  2.9305e-02,  5.9975e-02, -1.6664e-02, -2.7654e-02, -5.5292e-02, -5.2705e-02,  1.7376e-02,  3.3703e-02, -2.8344e-02,  1.3623e-02,\n",
      "         -6.1272e-02,  1.7236e-02, -2.5379e-02, -6.1715e-02, -2.6844e-03, -9.0166e-02, -8.1013e-02, -3.6099e-02,  1.6340e-02, -9.4729e-03,  6.4595e-02, -1.5547e-02,  8.3262e-02,  8.5267e-02, -4.1285e-02,  5.1265e-02, -3.3741e-02, -3.8084e-02,  3.4698e-02,  1.0667e-02,  6.8611e-02,  8.3447e-04,\n",
      "          5.2190e-02,  6.3809e-03,  8.0560e-02,  3.8266e-02, -4.0784e-02,  1.6232e-02,  5.8650e-02, -8.8082e-02, -9.0244e-02,  1.1361e-02, -7.6133e-02, -4.6376e-02, -1.3536e-03,  8.8909e-02, -5.5091e-02,  3.9260e-02, -8.9820e-02,  7.0665e-02, -7.6580e-02, -4.9347e-02,  3.0208e-02, -1.0161e-02,\n",
      "          6.8252e-02,  2.3033e-02,  6.2900e-02,  4.8745e-02,  7.2274e-02,  9.6165e-02,  7.8269e-05, -7.0609e-02,  9.3458e-02,  3.4084e-02,  6.0877e-02, -4.1466e-02, -3.6897e-03,  3.2344e-03,  6.6475e-03, -1.8404e-02,  5.9925e-02,  7.9803e-02, -1.0214e-02, -2.2673e-02,  5.3277e-02,  7.9631e-02,\n",
      "         -1.5263e-02,  6.0234e-02, -6.8944e-02, -5.4547e-02,  8.8221e-02,  2.5488e-02,  8.5602e-03, -7.1271e-02, -1.2722e-02, -7.2317e-02,  5.1623e-02,  6.2232e-02],\n",
      "        [ 2.9157e-03,  5.6055e-02,  9.6794e-02,  8.8709e-02, -4.6573e-02, -9.1998e-02,  6.1429e-02, -2.5780e-02,  6.3914e-02, -6.1590e-03, -3.1789e-03, -1.2537e-02,  4.0210e-02, -6.8660e-02,  9.5957e-02, -8.2417e-02,  9.5976e-02, -7.5864e-02,  4.0975e-02,  4.3686e-02, -3.5945e-02, -7.2976e-02,\n",
      "          4.1555e-02, -5.7239e-02,  9.7566e-02, -2.9023e-02, -2.8334e-02,  8.7518e-03,  2.9194e-02, -3.3832e-02,  8.3112e-03, -4.3468e-02,  9.6756e-02, -1.6707e-02,  4.0426e-02, -2.6456e-02, -1.9619e-02, -4.9521e-03, -1.3006e-03,  9.1375e-02, -2.7417e-03,  2.1330e-02, -5.8453e-02,  4.9311e-02,\n",
      "         -5.4771e-02, -3.7149e-03, -7.6079e-02, -8.1318e-02,  7.3137e-02,  7.1941e-02, -6.3941e-02, -8.4085e-02, -4.5678e-02, -6.0235e-02,  1.1898e-02,  5.6508e-03, -3.1006e-02, -7.9010e-02,  6.8291e-02, -8.1265e-02,  3.9412e-02,  4.7998e-02, -2.5191e-02, -3.7772e-02, -5.1825e-02, -4.4556e-02,\n",
      "         -1.9490e-02, -3.3089e-02,  7.2206e-02,  5.6407e-03, -5.0944e-03, -7.4075e-02,  9.8064e-03, -1.3785e-02, -9.7424e-02, -1.8039e-02, -2.7742e-02, -5.8623e-02,  1.9904e-02, -9.0868e-02,  3.7735e-02, -8.1524e-02,  2.5936e-02,  5.6523e-02,  1.4072e-02, -6.3261e-02,  3.9255e-02, -2.4760e-02,\n",
      "         -6.5023e-02,  1.8723e-02,  1.6895e-02, -8.4900e-02, -3.2197e-02,  4.4244e-02, -6.9660e-02,  1.8886e-02,  6.7671e-02,  5.1658e-02,  1.2269e-02, -7.5298e-03],\n",
      "        [-5.7958e-02,  4.1223e-02,  3.3258e-02,  2.4176e-02, -8.3467e-02,  5.2552e-02, -8.8468e-02,  3.9051e-02,  2.6473e-02, -5.9958e-02, -5.9589e-02, -2.3843e-02,  3.4276e-04, -4.0373e-02, -4.0309e-02,  2.1904e-02, -8.6213e-02,  8.6798e-02,  9.6572e-02,  2.3592e-02, -6.5535e-02, -9.8597e-03,\n",
      "         -6.6684e-02, -2.1954e-02,  5.0778e-02,  5.2211e-02,  1.3665e-02, -6.4869e-02,  7.1237e-02, -9.1893e-02, -4.3828e-02,  4.7075e-02,  5.1846e-02, -5.0716e-02,  6.3073e-02,  9.5760e-02, -6.7148e-02,  5.1317e-02, -2.9750e-02, -8.4698e-02,  4.0958e-02, -3.1558e-02, -4.6482e-02,  5.7485e-03,\n",
      "         -1.2638e-02,  2.9441e-02,  2.0428e-02,  5.8984e-02, -4.9043e-02,  4.4069e-03, -8.7641e-02, -2.8408e-02, -9.8357e-02, -1.8995e-02,  3.7520e-02, -5.0367e-02,  7.5657e-03, -1.8216e-02, -2.8238e-02, -4.0156e-02, -1.4857e-02,  6.4317e-02, -7.7543e-02,  6.1499e-03, -4.8616e-02, -4.7900e-02,\n",
      "         -6.4203e-02,  1.7517e-03, -8.6192e-02, -2.3361e-02,  1.6597e-02,  9.5858e-04,  1.4544e-03, -6.6451e-02, -5.5225e-02, -7.6215e-02, -6.2670e-02,  4.0125e-02, -5.5549e-02,  7.0316e-02, -8.6830e-02, -8.8830e-02,  9.3810e-02, -8.8104e-02, -4.5038e-02,  7.4599e-02,  4.2483e-02, -4.8183e-02,\n",
      "          9.4398e-02,  5.1596e-02,  3.5604e-02,  6.6509e-02, -1.4827e-02,  3.7576e-02, -1.3673e-02,  1.0364e-02,  3.7518e-02, -3.3276e-02, -6.0702e-02, -7.8505e-02],\n",
      "        [-7.0806e-02,  1.9528e-02,  7.9112e-02,  9.2194e-02,  2.2606e-02, -6.1248e-02, -7.6824e-02, -9.9314e-02,  4.2628e-03,  8.4848e-02, -9.1161e-02,  4.7416e-02,  9.4516e-02,  9.2321e-02, -6.5316e-02,  2.5383e-03,  4.0660e-02,  3.6348e-02,  9.6962e-03, -5.3137e-02,  9.9131e-02, -1.0011e-02,\n",
      "         -2.9367e-02, -6.7517e-02,  5.6093e-02,  1.2592e-02, -6.0802e-02,  2.3738e-02, -1.2006e-02,  1.9146e-02,  1.9826e-02, -3.9721e-02,  1.5467e-02, -2.0978e-02, -3.7055e-02, -8.5840e-02, -4.2528e-02,  2.8142e-02,  5.8122e-02,  9.2850e-02, -4.9655e-02, -5.1144e-02, -7.8042e-02, -2.0670e-03,\n",
      "         -9.6393e-02, -2.6747e-02,  9.6948e-02, -3.9675e-02, -4.4481e-03, -5.5131e-02,  7.6082e-02,  2.9504e-04, -8.1175e-02, -9.6278e-02, -4.0882e-02,  1.0443e-02, -7.3982e-03, -2.3223e-03, -9.5432e-02, -4.9596e-02,  3.5534e-03, -8.9883e-02,  6.1658e-02,  7.2381e-02, -7.2006e-02,  6.0297e-02,\n",
      "          8.7148e-02, -6.1348e-02, -3.3596e-02, -5.2586e-02, -8.8746e-02,  4.4521e-02,  3.3675e-02,  9.2828e-02,  8.4219e-02,  9.5528e-02, -4.7088e-02, -9.4617e-02, -5.2068e-02, -3.5680e-02,  1.3824e-02,  8.1546e-03, -3.6643e-02,  1.6128e-02, -5.2901e-02, -4.8015e-02,  9.0286e-02,  8.1614e-02,\n",
      "         -6.1675e-02, -3.3909e-02,  8.4584e-02,  1.2338e-02, -7.2733e-02,  3.2539e-02,  5.2265e-02,  5.5847e-02, -3.8760e-02, -7.8528e-02, -3.1608e-02,  2.6734e-02],\n",
      "        [-2.7049e-03,  4.0648e-02,  2.4674e-03,  6.8195e-02, -8.8738e-02,  5.6129e-02, -1.5411e-02,  9.1881e-03,  9.7794e-02, -9.4262e-03,  6.1682e-03, -9.8068e-02, -2.5245e-02,  5.7455e-02,  5.9371e-02,  9.6437e-02,  5.6362e-02, -2.3968e-02, -1.7488e-02, -1.0225e-01, -2.0857e-02,  6.7612e-02,\n",
      "          8.4923e-02,  2.8899e-02, -1.4809e-02,  8.7590e-02, -5.3130e-02, -3.4333e-02,  5.6529e-02,  2.7098e-02,  7.3205e-02, -9.2251e-02,  9.7097e-02, -1.0446e-01,  1.6861e-02,  2.0144e-02,  7.7008e-02,  1.1590e-02,  4.8089e-02, -7.3353e-02,  2.3495e-02, -9.7783e-02,  7.3386e-02,  4.1560e-02,\n",
      "          3.8082e-03,  4.0820e-02, -3.1602e-02,  2.1909e-02, -3.3278e-02, -5.6469e-02, -5.7730e-02, -5.9628e-02,  3.5612e-02, -1.6597e-02, -1.3235e-02,  3.8480e-02,  9.1647e-02, -9.0983e-02,  5.1511e-03, -5.2126e-03, -3.2267e-02,  6.2603e-02,  1.2769e-02, -5.1266e-02, -1.1596e-02,  1.8878e-02,\n",
      "         -9.5196e-02,  2.0703e-02, -2.3528e-02,  8.2110e-03, -7.3043e-02, -3.5532e-02,  9.3778e-02,  7.8817e-02,  4.2138e-02,  8.2070e-02,  8.0160e-02, -5.8009e-02, -7.9464e-02,  1.6002e-02,  4.7954e-02,  5.0394e-02,  5.0237e-02, -7.0317e-02, -7.9604e-02,  9.6801e-02, -2.8167e-02,  3.6113e-02,\n",
      "         -9.2220e-02,  8.9567e-02,  2.2855e-02, -2.6284e-02,  5.3701e-02, -1.1453e-02, -1.0354e-02, -3.0723e-02,  4.9730e-02,  3.5279e-02, -8.1051e-02, -1.4690e-02],\n",
      "        [-3.4583e-02,  1.1256e-02,  1.9576e-02, -6.6168e-02, -2.3802e-02,  3.1979e-02, -3.0809e-02,  2.0356e-02, -8.7797e-02, -5.8978e-02,  6.3065e-02, -3.8816e-02,  6.2343e-02, -6.7134e-02,  8.6277e-03,  7.2274e-02, -4.6661e-02,  7.4294e-02,  4.8852e-02,  8.3362e-02, -9.7913e-02,  8.7636e-03,\n",
      "         -2.0835e-02,  1.6769e-02,  3.2772e-02,  6.0054e-02, -6.3349e-02,  6.8142e-02,  6.4682e-02,  7.9257e-02,  4.3060e-02, -8.9962e-02,  9.7855e-03,  1.2936e-02,  8.0460e-02, -6.1465e-02, -1.3236e-02, -8.8466e-02,  8.1589e-02,  1.0621e-02, -6.6912e-02,  8.5506e-02,  7.5354e-02,  6.0412e-02,\n",
      "         -7.8735e-02,  6.0373e-02, -3.2830e-02,  7.3749e-02, -1.6702e-02, -1.6599e-02, -5.3302e-02, -7.0469e-03, -2.4857e-02, -1.9594e-02,  7.1090e-02, -6.2775e-02, -7.4433e-02, -6.4044e-02,  4.6828e-02, -8.6164e-02, -3.1575e-02, -4.3656e-02, -1.6719e-02, -2.1659e-02, -6.8448e-02,  8.2961e-02,\n",
      "          2.5517e-02, -2.5224e-03, -7.3195e-02, -5.3417e-02,  5.1799e-02,  8.9236e-02,  6.6561e-02,  6.7163e-02, -9.0238e-02,  8.1130e-02, -8.0834e-02,  7.9779e-02, -1.7539e-02, -2.4548e-02, -2.9035e-02,  7.7136e-02,  6.8428e-02, -3.1012e-02, -7.7799e-02,  3.3791e-02, -6.5279e-02, -7.8427e-02,\n",
      "         -8.4862e-02, -6.1919e-02,  8.1921e-02, -5.8071e-03, -2.3921e-02,  7.3868e-02,  7.4242e-02,  2.2550e-02, -6.4205e-02,  1.6643e-02, -8.9121e-02, -8.3160e-02],\n",
      "        [ 8.9528e-02, -9.1389e-02,  2.1749e-02,  2.9251e-02, -3.5793e-02,  3.7394e-02, -4.2589e-02, -1.5377e-02,  8.7851e-02, -2.3422e-03,  3.1905e-02, -6.9283e-02,  9.9098e-02, -2.0144e-03,  3.2527e-02,  5.5307e-04, -3.5258e-02, -3.0613e-02, -9.7984e-02,  2.4462e-03, -1.7607e-02, -6.7992e-02,\n",
      "          4.2443e-02,  2.1657e-02,  9.0391e-02, -7.8553e-02,  2.3069e-02,  7.0150e-02,  6.8550e-02, -4.4383e-02,  4.6650e-02,  9.4722e-02,  7.8054e-02,  3.5866e-02, -7.4813e-02,  3.7717e-03,  4.5975e-02, -6.5378e-02, -2.7640e-02, -1.0257e-01, -6.9314e-02,  7.3138e-03, -1.3564e-02,  5.8091e-02,\n",
      "          1.0621e-02, -6.6638e-02,  2.4521e-02, -7.7230e-02,  1.8576e-02,  6.1202e-02,  5.1003e-02,  5.7684e-02, -3.9525e-02, -3.0707e-02,  6.7633e-02,  1.5242e-03,  4.2874e-05,  7.8010e-02,  5.3540e-02,  4.3432e-02,  6.2001e-02,  2.3205e-02, -9.4486e-02,  4.4010e-02, -6.8593e-03,  3.4930e-03,\n",
      "         -3.9809e-02,  6.4229e-02, -7.6459e-02,  4.7818e-02, -9.6292e-02,  3.3370e-02, -7.0695e-02, -3.5479e-02,  7.8103e-02,  1.0065e-01,  2.0055e-02,  4.9472e-02, -1.0010e-02,  7.7368e-02, -6.5163e-02, -1.8421e-02,  2.2431e-02,  8.2636e-02, -1.4995e-03, -1.7607e-02, -7.5099e-02,  7.4428e-02,\n",
      "         -5.5459e-02, -1.0230e-02, -3.4877e-02, -1.1054e-02,  3.9911e-02,  3.2602e-02, -7.3853e-02, -1.9820e-02,  7.6663e-02,  1.8607e-02,  5.4375e-02,  5.9019e-02]], device='cuda:0')\n",
      "fc2.bias \t tensor([-0.0235, -0.0609, -0.0477, -0.0584,  0.0672,  0.0955, -0.0978,  0.0314, -0.0742, -0.0432], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in my_trained_cnn_model.state_dict():\n",
    "    print(i, \"\\t\", my_trained_cnn_model.state_dict()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271734ee-83bc-41f0-9a2e-7a7a5c9cebee",
   "metadata": {},
   "source": [
    "**Use saved trained model for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eebcd111-0b17-4fe4-971c-7044d9f482f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trained_cnn_model = my_trained_cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37e3ee76-499c-462f-af10-ef21fca32b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(my_trained_cnn_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8729b5-3ff0-4fb0-9dfd-6e4ff0f4bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual labels for comparison\n",
    "\n",
    "dataiter = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "138913d1-39ae-49af-b28e-8f9ba27b9cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- outputs ----------\n",
      "tensor([[-1.2500, -0.3900,  1.1400,  1.7300,  0.4700,  1.6300,  1.3400, -2.6300, -0.3000, -2.0300],\n",
      "        [ 4.1600,  5.9700, -0.9300, -0.5600, -3.0200, -3.4200, -4.0400, -2.7100,  5.3300,  5.9300],\n",
      "        [ 2.4100,  2.2900, -0.9900,  1.1800, -1.1600, -1.4100, -4.5600, -2.0700,  2.4200,  3.8700],\n",
      "        [ 2.4500,  2.1300,  0.6400, -0.2900, -0.5600, -1.2500, -0.5600,  0.4900,  3.5800,  1.0900],\n",
      "        [ 0.0600, -0.8100,  3.0300,  2.0900,  4.5700,  2.2400,  3.8300,  2.0300, -0.2900, -1.3200],\n",
      "        [-1.1500,  0.8900,  0.8500,  2.3200,  0.8300,  1.6300,  2.6300,  0.1700, -2.3200,  1.1800],\n",
      "        [-0.7100,  5.0800,  0.7000,  4.0500, -1.8800,  0.2700, -0.3100, -0.7400, -1.0700,  3.7900],\n",
      "        [ 0.4400, -0.4700,  2.6900,  2.4100,  2.1000,  0.7600,  4.0800,  1.0000, -1.6600, -1.5000],\n",
      "        [ 1.1100, -1.2700,  2.7700,  2.9500,  2.5600,  3.3700,  0.7000,  1.6800, -1.7400, -2.2600],\n",
      "        [ 3.7000,  7.3900,  0.3100,  0.8400, -2.6000, -2.1200, -2.3100, -1.8600,  3.4100,  4.3900],\n",
      "        [ 2.6100, -0.8000,  0.4100,  1.2900, -0.1900,  2.3000, -2.9100, -0.6200,  3.4900, -1.3300],\n",
      "        [-0.2500,  4.5600, -0.8500, -0.7300, -2.1400, -1.3300, -2.0900,  0.3800,  0.7800,  7.1500],\n",
      "        [ 0.3800,  1.5700,  1.2300,  2.3900,  1.4500,  2.4000,  0.7800,  0.5400, -1.9100, -0.5600],\n",
      "        [ 0.5600,  3.3400,  0.6300, -0.0200, -1.2800, -0.8500,  2.1500,  0.6300, -0.9200,  1.4600],\n",
      "        [ 1.2200,  6.7300,  0.6100, -0.7600, -1.6800, -1.8700, -2.0700,  0.5700,  1.8100,  6.5100],\n",
      "        [ 0.6300, -0.6500,  1.3900,  0.1700,  1.8400,  1.7800,  1.7100, -0.0300,  2.0500, -0.9100],\n",
      "        [ 0.4000,  0.6700,  0.7100,  2.3100,  0.1200,  3.7700, -0.9600,  2.2100,  1.3500, -1.3700],\n",
      "        [-0.2100, -1.3300,  0.1900,  0.8700,  1.8400,  1.6600,  1.3700,  2.0100, -0.4300,  0.8700],\n",
      "        [ 1.3100,  2.3100, -2.7300,  0.0200, -3.8100, -1.9400, -2.2800, -2.1400,  6.3400,  3.6900],\n",
      "        [-1.4000, -0.1900,  2.5700,  2.4700,  2.9900,  0.8600,  5.9900,  2.1400, -2.2100,  0.0000],\n",
      "        [ 1.7200,  0.6800,  1.5000, -0.2000,  2.5200,  1.0300,  0.0200,  5.2400, -1.5900,  0.9700],\n",
      "        [ 6.9100,  0.0100,  4.0700,  1.4800,  2.2800,  1.0300, -1.2600,  2.0100,  1.4000, -0.9100],\n",
      "        [ 2.1900, -0.6200,  2.3900,  0.8400,  0.8500, -0.7800, -2.1700, -1.3700,  1.1100, -1.1100],\n",
      "        [-0.5300,  7.9100, -5.2300, -2.9000, -2.3700,  1.1400,  0.7200,  2.1700,  1.0900,  6.3500]], device='cuda:0')\n",
      "---------- highest energy ----------\n",
      "torch.return_types.max(\n",
      "values=tensor([1.7327, 5.9681, 3.8721, 3.5766, 4.5680, 2.6252, 5.0832, 4.0782, 3.3709, 7.3892, 3.4930, 7.1477, 2.4039, 3.3377, 6.7292, 2.0531, 3.7675, 2.0116, 6.3448, 5.9934, 5.2396, 6.9136, 2.3949, 7.9118], device='cuda:0'),\n",
      "indices=tensor([3, 1, 9, 8, 4, 6, 1, 6, 5, 1, 8, 9, 5, 1, 1, 8, 5, 7, 8, 6, 7, 0, 2, 1], device='cuda:0'))\n",
      "---------- predicted ----------\n",
      "tensor([3, 1, 9, 8, 4, 6, 1, 6, 5, 1, 8, 9, 5, 1, 1, 8, 5, 7, 8, 6, 7, 0, 2, 1], device='cuda:0')\n",
      "---------- actual ----------\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9], device='cuda:0')\n",
      "---------- total ----------\n",
      "24\n",
      "---------- correct ----------\n",
      "14\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "---------- outputs ----------\n",
      "tensor([[ 1.5000, -2.2200,  3.6700,  1.9100,  4.3000,  3.1400,  1.7700,  3.1000, -1.6300, -2.3400],\n",
      "        [-0.9900, -1.4400,  3.2300, -0.5800,  2.3900,  0.4400,  2.8100, -0.2300, -1.0900, -1.6600],\n",
      "        [ 0.3600, -0.2200,  1.0900,  2.2500,  2.0500,  1.5000,  1.5600,  1.3700, -1.3500, -0.3200],\n",
      "        [ 1.8100, -0.7000,  1.2500,  0.7100,  1.0600,  0.3600,  0.0800,  1.7800, -0.2100,  1.0400],\n",
      "        [ 0.9800,  6.6900, -0.1800,  0.7500, -0.3900,  1.1300, -0.7100,  1.8400, -1.4800,  5.0200],\n",
      "        [ 0.4800,  0.8000,  1.4900,  0.8700,  1.2400,  2.5800,  1.3900,  2.3200, -3.9800,  0.1100],\n",
      "        [-1.1600,  1.8400, -0.1600,  0.8200, -0.8500,  1.3600,  1.6000,  1.3000, -3.0300,  0.6500],\n",
      "        [ 1.6500, -1.8300,  2.9200,  2.9400,  2.6700,  4.2400,  0.2300,  1.8500, -0.8200, -2.2700],\n",
      "        [ 1.0400, -0.3500,  2.0000,  1.3200,  1.8200,  0.9900,  1.9300,  1.6200, -0.0400, -0.8000],\n",
      "        [ 0.0200, -0.1800,  1.8400,  2.5200,  0.9000,  2.1600,  2.2500,  1.3700, -1.8000, -1.9300],\n",
      "        [ 1.5700,  0.7800, -0.4500, -0.6000, -0.1500, -1.1800, -2.7000,  2.0000,  1.6100,  3.3900],\n",
      "        [ 1.0000,  4.6200, -0.8200, -0.9900, -1.7200, -1.7400, -0.6200,  0.5800,  0.4200,  3.9900],\n",
      "        [ 1.3400,  1.0100,  1.0300,  2.1300,  1.8600,  1.6900,  2.1900,  2.2200, -2.2300, -0.0300],\n",
      "        [ 2.2000,  5.6100, -2.7100, -0.4000, -1.4800, -1.3700,  0.2100, -0.5500,  4.0600,  5.1700],\n",
      "        [ 2.0600,  6.3400, -1.3300, -0.4900, -0.9100, -0.8900,  1.4700,  0.3100,  0.9600,  4.5400],\n",
      "        [ 0.6100, -1.4000,  2.0500,  2.6600,  1.0800,  3.4400,  0.5300, -0.2600,  1.3600, -2.7400],\n",
      "        [ 3.5800,  2.4000,  1.3700,  0.2300,  2.5900, -0.1900, -0.8500,  3.6700,  2.3200,  2.8500],\n",
      "        [-0.9700, -1.6500,  2.0100,  1.6800,  0.9600,  0.7700,  3.7700,  0.9000, -0.7000, -0.8900],\n",
      "        [ 0.7000,  2.1900, -0.7800,  1.4300, -0.9600,  0.3200, -0.3400,  0.9700, -0.7300,  3.1400],\n",
      "        [-0.2100,  0.3500,  0.9300,  2.1400,  1.7600,  1.6500,  2.5400,  0.4800, -1.5300,  0.1200],\n",
      "        [ 2.4500,  2.9500,  0.6500, -3.1300,  0.1600, -5.0500, -8.6300,  0.9200,  2.3600,  5.3000],\n",
      "        [ 4.1900,  3.7800,  0.1400, -0.8600, -0.2400, -1.1200, -2.7800,  1.7700,  5.0600,  5.7800],\n",
      "        [-0.6800,  0.1700,  2.7400,  5.0100,  1.4900,  3.9500,  1.9200, -0.0100, -0.2600, -0.6900],\n",
      "        [-0.4800,  0.5300, -0.6300,  1.1300, -1.0100,  1.8500, -1.3600,  2.7200, -0.3900,  1.0900]], device='cuda:0')\n",
      "---------- highest energy ----------\n",
      "torch.return_types.max(\n",
      "values=tensor([4.2967, 3.2301, 2.2510, 1.8136, 6.6924, 2.5769, 1.8368, 4.2389, 1.9990, 2.5180, 3.3862, 4.6248, 2.2240, 5.6081, 6.3409, 3.4410, 3.6651, 3.7682, 3.1423, 2.5405, 5.3023, 5.7848, 5.0111, 2.7210], device='cuda:0'),\n",
      "indices=tensor([4, 2, 3, 0, 1, 5, 1, 5, 2, 3, 9, 1, 7, 1, 1, 5, 7, 6, 9, 6, 9, 9, 3, 7], device='cuda:0'))\n",
      "---------- predicted ----------\n",
      "tensor([4, 2, 3, 0, 1, 5, 1, 5, 2, 3, 9, 1, 7, 1, 1, 5, 7, 6, 9, 6, 9, 9, 3, 7], device='cuda:0')\n",
      "---------- actual ----------\n",
      "tensor([5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9], device='cuda:0')\n",
      "---------- total ----------\n",
      "48\n",
      "---------- correct ----------\n",
      "24\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Accuracy: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = my_trained_cnn_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)   # class with highest energy choosen as prediction\n",
    "        print('---------- outputs ----------')\n",
    "        print(torch.round(outputs.data, decimals=2))\n",
    "        print('---------- highest energy ----------')\n",
    "        print(torch.max(outputs.data, 1))\n",
    "        print('---------- predicted ----------')\n",
    "        print(predicted.data)\n",
    "        images, labels = next(dataiter)\n",
    "        print('---------- actual ----------')\n",
    "        print(labels.data)\n",
    "        total = total + labels.size(0)\n",
    "        print('---------- total ----------')\n",
    "        print(total)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        print('---------- correct ----------')\n",
    "        print(correct)\n",
    "        print()\n",
    "        print('--------------------------------------------------------------------------------')\n",
    "        print()\n",
    "        i = i + 1\n",
    "        if i == 3:   # test on first 2 batches\n",
    "            break\n",
    "\n",
    "print()\n",
    "print(f'Accuracy: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
